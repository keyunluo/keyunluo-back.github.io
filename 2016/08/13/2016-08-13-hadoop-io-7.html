<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Coder On The Road"><title>Hadoop源码学习(11)——SequenceFile | 流光</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.1.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.2/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/2.2.3/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Hadoop源码学习(11)——SequenceFile</h1><a id="logo" href="/.">流光</a><p class="description">他跑啊跑啊，只为追上那个曾经被寄予厚望的自己</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/guestbook/"><i class="fa fa-comments"> 留言</i></a><a href="/resource/share"><i class="fa fa-download"> 资源</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Hadoop源码学习(11)——SequenceFile</h1><div class="post-meta">Aug 13, 2016<span> | </span><span class="category"><a href="/categories/SourceCodeLearning/">SourceCodeLearning</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-thread-key="2016/08/13/2016-08-13-hadoop-io-7.html" href="/2016/08/13/2016-08-13-hadoop-io-7.html#comments" class="ds-thread-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#SequenceFile类"><span class="toc-number">1.</span> <span class="toc-text">SequenceFile类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SequenceFile的格式"><span class="toc-number">2.</span> <span class="toc-text">SequenceFile的格式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SequenceFile写操作"><span class="toc-number">3.</span> <span class="toc-text">SequenceFile写操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SequenceFile读操作"><span class="toc-number">4.</span> <span class="toc-text">SequenceFile读操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#通过命令行接口显示SequenceFile"><span class="toc-number">5.</span> <span class="toc-text">通过命令行接口显示SequenceFile</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SequenceFile的排序和合并"><span class="toc-number">6.</span> <span class="toc-text">SequenceFile的排序和合并</span></a></li></ol></div></div><div class="post-content"><blockquote>
<p><strong>本节内容：</strong>SequenceFile为二进制键值对提供了一个持久数据结构，也可以作为小文件的容器，HDFS和MapReduce是针对大文件优化的，所以通过SequenceFile类型将小文件包装起来，可以获得更高效率的存储和处理。</p>
</blockquote>
<a id="more"></a>
<h2 id="SequenceFile类"><a href="#SequenceFile类" class="headerlink" title="SequenceFile类"></a>SequenceFile类</h2><p>SequenceFile类位于org.apache.hadoop.io包内，类结构如下：</p>
<p><img src="/resource/blog/2016-08/SequenceFile.png" alt="SequenceFile类"></p>
<h2 id="SequenceFile的格式"><a href="#SequenceFile的格式" class="headerlink" title="SequenceFile的格式"></a>SequenceFile的格式</h2><p>SequenceFile文件由文件头和随后的一条或多条记录组成。顺序文件的前三个字节是SEQ，紧随其后的一个字节表示顺序文件的版本号。文件头还包括其他字段，例如键和值类的名称、数据压缩细节、用户定义的元数据以及同步标识。同步标识用于在读取文件时能够从任意位置开始识别边界记录。</p>
<p>记录的内部结构取决于是否启用压缩。如果已经启用，则取决于记录压缩还是数据块压缩。</p>
<p>如果没有启用压缩(默认情况)，那么每条记录则由记录长度(字节数)、键长度、键和值组成。长度字段为4字节长的整数，遵循java.io.DataOutput类中的writeInt()方法的约定，写入顺序文件的类定义Serialization类来实现键和值的序列化。</p>
<p>记录压缩格式与无压缩情况基本相同，只不过值是用文件头定义的codec压缩的，但是键并没有被压缩。</p>
<p><img src="/resource/blog/2016-08/sequencefilewithnocompression.jpg" alt="SequenceFile-无压缩和记录压缩"></p>
<p>块压缩是指一次性压缩多条记录，因为它可以利用记录间的相似性进行压缩，所以相较于单条记录压缩方法，该方法的压缩效率更高，如下图所示。可以不断向数据块中压缩记录，直到块的字节数不小于io.seqfile.compress.blocksize属性中设置的字节数：默认为1MB。每一个新块的开始处都需要插入同步标识。数据块的格式如下：首先是一个指示数据块中字节数的字段；紧接着是4个压缩字段(键长度、键、值长度和值)</p>
<p><img src="/resource/blog/2016-08/sequencefilewithblockcompression.jpg" alt="SequenceFile-块压缩"></p>
<h2 id="SequenceFile写操作"><a href="#SequenceFile写操作" class="headerlink" title="SequenceFile写操作"></a>SequenceFile写操作</h2><p>通过createWriter()静态方法可以创建SequenceFile对象，并返回SequenceFile.Writer实例。该静态方法有多个重载版本，但都需要指定待写入的数据流(FSDataOutputStream或FileSystem对象和Path对象)，Configuration对象，以及键和值的类型，写入的参数信息等。另外，可选参数包括压缩类型以及相应的codec,Progressable回调函数用于通知写入的进度，以及在SequenceFile头文件中存储的Metadata实例。</p>
<p>存储在SequenceFile中的键和值并不一定需要是Writable类型，只要能被Serialization序列化和反序列化，任何类型都可以。</p>
<p>一旦拥有SequenceFile.Writer实例，就可以通过append()方法在文件末尾附加键值对。写完后，可以调用close()方法(SequenceFile.Writer实现了java.io.Closable接口)。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.SequenceFile;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SequenceFileWriteDemo</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String[] DATA = &#123;</span><br><span class="line">    <span class="string">"One, two, buckle my shoe"</span>,</span><br><span class="line">    <span class="string">"Three, four, shut the door"</span>,</span><br><span class="line">    <span class="string">"Five, six, pick up sticks"</span>,</span><br><span class="line">    <span class="string">"Seven, eight, lay them straight"</span>,</span><br><span class="line">    <span class="string">"Nine, ten, a big fat hen"</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">    String url = args[<span class="number">0</span>];</span><br><span class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    FileSystem fs = FileSystem.get(URI.create(url),conf);</span><br><span class="line">    Path path = <span class="keyword">new</span> Path(url);</span><br><span class="line"></span><br><span class="line">    IntWritable key = <span class="keyword">new</span> IntWritable();</span><br><span class="line">    Text value = <span class="keyword">new</span> Text();</span><br><span class="line">    SequenceFile.Writer writer = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">        writer = SequenceFile.createWriter(fs,conf,path,key.getClass(),value.getClass());</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">1024</span>;i++)&#123;</span><br><span class="line">            key.set(<span class="number">1024</span>-i);</span><br><span class="line">            value.set(DATA[i % DATA.length]);</span><br><span class="line">            writer.append(key,value);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span>&#123;</span><br><span class="line">        IOUtils.closeStream(writer);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译与运行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">➜  project export CLASSPATH=$HADOOP_CLASSPATH:$CLASSPATH</span><br><span class="line">➜  project javac SequenceFileWriteDemo.java</span><br><span class="line">➜  project java SequenceFileWriteDemo numbers.seq</span><br></pre></td></tr></table></figure>
<h2 id="SequenceFile读操作"><a href="#SequenceFile读操作" class="headerlink" title="SequenceFile读操作"></a>SequenceFile读操作</h2><p>从头到尾读取顺序文件不外乎创建SequenceFile.Reader实例后反复调用next()方法迭代读取记录。读取的是哪条记录与你使用的序列化框架有关。如果使用Writable类型，那么通过键和值作为参数的next()方法可以将数据流中的下一条键值对读入变量中。<code>public boolean next(Writable key,Writable val)</code>。对于其他非Writable类型的序列化框架，例如Apache Thrift，则应该使用下面两个方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">next</span><span class="params">(Object key)</span> <span class="keyword">throws</span> IOException</span><br><span class="line"><span class="keyword">public</span> Object <span class="title">getCurrentValue</span><span class="params">(Object val)</span> <span class="keyword">throws</span> IOException</span></span><br></pre></td></tr></table></figure>
<p>在这种情况下，需要确保io.serializations属性已经设置了你想要的序列化框架。如果next()方法返回的是非null对象，则可以从数据流中读取键、值对，并且可以通过getCurrentValue()方法读取该值。否则，如果next()返回null值，表示已经读到文件末尾。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Writable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.SequenceFile;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.ReflectionUtils;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SequenceFileReadDemo</span></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">    String url = args[<span class="number">0</span>];</span><br><span class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    FileSystem fs = FileSystem.get(URI.create(url),conf);</span><br><span class="line">    Path path = <span class="keyword">new</span> Path(url);</span><br><span class="line"></span><br><span class="line">    SequenceFile.Reader reader = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">        reader = <span class="keyword">new</span> SequenceFile.Reader(fs,path,conf);</span><br><span class="line">        Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(),conf);</span><br><span class="line">        Writable value = (Writable) ReflectionUtils.newInstance(reader.getValueClass(),conf);</span><br><span class="line">        <span class="keyword">long</span> position = reader.getPosition();</span><br><span class="line">        <span class="keyword">while</span> (reader.next(key,value))&#123;</span><br><span class="line">            String syncSeen = reader.syncSeen() ? <span class="string">"*"</span> : <span class="string">" "</span>;</span><br><span class="line">            System.out.printf(<span class="string">"[%s%s]\t%s\t%s\n"</span>,position,syncSeen,key,value);</span><br><span class="line">            position = reader.getPosition();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span>&#123;</span><br><span class="line">        IOUtils.closeStream(reader);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="通过命令行接口显示SequenceFile"><a href="#通过命令行接口显示SequenceFile" class="headerlink" title="通过命令行接口显示SequenceFile"></a>通过命令行接口显示SequenceFile</h2><p>hdfs dfs命令有一个-text选项可以以文本形式显示顺序文件，该选项可以查看文件的代码，由此检测出文件的类型并将其转换成相应的文本。该选项可以识别gzip压缩文件和顺序文件；否则，假设输入为纯文本文件。</p>
<p>对于顺序文件，如果键和值是由具体含义的字符串表示，那么这个命令就非常有用(通过toString()方法定义)，同样，如果有自己定义的键或值的类，则应该确保它们在Hadoop类路径目录下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">➜  project hdfs dfs -text numbers.seq | head</span><br><span class="line"><span class="number">16</span>/<span class="number">08</span>/<span class="number">13</span> <span class="number">16</span>:<span class="number">39</span>:<span class="number">23</span> INFO zlib.ZlibFactory: Successfully loaded &amp; initialized native-zlib library</span><br><span class="line"><span class="number">16</span>/<span class="number">08</span>/<span class="number">13</span> <span class="number">16</span>:<span class="number">39</span>:<span class="number">23</span> INFO compress.CodecPool: Got brand-new decompressor [.deflate]</span><br><span class="line"><span class="number">1024</span>    One, two, buckle my shoe</span><br><span class="line"><span class="number">1023</span>    Three, four, shut the door</span><br><span class="line"><span class="number">1022</span>    Five, six, pick up sticks</span><br><span class="line"><span class="number">1021</span>    Seven, eight, lay them straight</span><br><span class="line"><span class="number">1020</span>    Nine, ten, a big fat hen</span><br><span class="line"><span class="number">1019</span>    One, two, buckle my shoe</span><br><span class="line"><span class="number">1018</span>    Three, four, shut the door</span><br><span class="line"><span class="number">1017</span>    Five, six, pick up sticks</span><br><span class="line"><span class="number">1016</span>    Seven, eight, lay them straight</span><br><span class="line"><span class="number">1015</span>    Nine, ten, a big fat hen</span><br></pre></td></tr></table></figure>
<h2 id="SequenceFile的排序和合并"><a href="#SequenceFile的排序和合并" class="headerlink" title="SequenceFile的排序和合并"></a>SequenceFile的排序和合并</h2><p>MapReduce是对多个顺序文件进行排序或合并的最有效的方法。MapReduce本身是并行的，并且可由用户指定要使用多少个reducer，该数决定这输出分区数。例如，通过指定一个reducer，可以得到一个输出文件。</p>
<p>除了MapReduce实现排序/归并，还有一种方法是使用SequenceFile.Sorter类中的sort()方法和merge()方法。它们比MapReduce更早出现，比MapReduce更底层，为了实现并行，需要手动对数据进行分区，因此不建议使用。</p>
</div><script type="text/javascript" src="/js/share.js?v=1.0.0" async></script><a data-url="http://keyunluo.github.io/2016/08/13/2016-08-13-hadoop-io-7.html" data-id="citgwlyu5003wndgljh37jgd9" class="article-share-link">分享到</a><div class="tags"><a href="/tags/Hadoop/">Hadoop</a></div><div class="post-nav"><a href="/2016/08/13/2016-08-13-hadoop-io-8.html" class="pre">Hadoop源码学习(12)——MapFile</a><a href="/2016/08/12/2016-08-12-hadoop-io-6.html" class="next">Hadoop源码学习(10)——Avro(2)</a></div><div data-thread-key="2016/08/13/2016-08-13-hadoop-io-7.html" data-title="Hadoop源码学习(11)——SequenceFile" data-url="http://keyunluo.github.io/2016/08/13/2016-08-13-hadoop-io-7.html" class="ds-share flat"><div class="ds-share-inline"><ul class="ds-share-icons-16"><li data-toggle="ds-share-icons-more"><a href="javascript:void(0);" class="ds-more">分享到：</a></li><li><a href="javascript:void(0);" data-service="weibo" class="ds-weibo">微博</a></li><li><a href="javascript:void(0);" data-service="qzone" class="ds-qzone">QQ空间</a></li><li><a href="javascript:void(0);" data-service="qqt" class="ds-qqt">腾讯微博</a></li><li><a href="javascript:void(0);" data-service="wechat" class="ds-wechat">微信</a></li></ul><div class="ds-share-icons-more"></div></div></div><div data-thread-key="2016/08/13/2016-08-13-hadoop-io-7.html" data-title="Hadoop源码学习(11)——SequenceFile" data-url="http://keyunluo.github.io/2016/08/13/2016-08-13-hadoop-io-7.html" data-author-key="1" class="ds-thread"></div></div></div></div><div class="pure-u-1-4"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/AlgorithmApplication/">AlgorithmApplication</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/BigData/">BigData</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DataBase/">DataBase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Life/">Life</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MachineLearning/">MachineLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Programming/">Programming</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/SourceCodeLearning/">SourceCodeLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tools/">Tools</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/毕业/" style="font-size: 15px;">毕业</a> <a href="/tags/Oracle/" style="font-size: 15px;">Oracle</a> <a href="/tags/sqoop/" style="font-size: 15px;">sqoop</a> <a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/VPN/" style="font-size: 15px;">VPN</a> <a href="/tags/二次排序/" style="font-size: 15px;">二次排序</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/elasticsearch/" style="font-size: 15px;">elasticsearch</a> <a href="/tags/大数据/" style="font-size: 15px;">大数据</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/生活/" style="font-size: 15px;">生活</a> <a href="/tags/DataBase/" style="font-size: 15px;">DataBase</a> <a href="/tags/UML/" style="font-size: 15px;">UML</a> <a href="/tags/PlantUML/" style="font-size: 15px;">PlantUML</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/Markdown/" style="font-size: 15px;">Markdown</a> <a href="/tags/Latex/" style="font-size: 15px;">Latex</a> <a href="/tags/CentOS/" style="font-size: 15px;">CentOS</a> <a href="/tags/Cloudera/" style="font-size: 15px;">Cloudera</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/数据压缩/" style="font-size: 15px;">数据压缩</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/09/24/2016-09-24-compress-1.html">数据压缩(1) —— 概述</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/23/2016-09-23-statical-learning-5.html">统计学习方法——决策树</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/22/2016-09-22-hadoop-filesystem-1.html">Hadoop源码学习(15)——文件系统(1)</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/16/2016-08-16-statical-learning-4.html">统计学习方法——朴素贝叶斯法</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/15/2016-08-15-statical-learning-3.html">统计学习方法——K近邻算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/15/2016-08-15-hadoop-io-10.html">Hadoop源码学习(14)——压缩(2)</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/14/2016-08-14-hadoop-io-9.html">Hadoop源码学习(13)——压缩(1)</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/13/2016-08-13-hadoop-io-8.html">Hadoop源码学习(12)——MapFile</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/13/2016-08-13-hadoop-io-7.html">Hadoop源码学习(11)——SequenceFile</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/12/2016-08-12-hadoop-io-6.html">Hadoop源码学习(10)——Avro(2)</a></li></ul></div><div class="widget"><div class="comments-title"><i class="fa fa-comment-o"> 最近评论</i></div><div data-num-items="5" data-show-avatars="0" data-show-time="1" data-show-admin="0" data-excerpt-length="32" data-show-title="1" class="ds-recent-comments"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 外部链接</i></div><ul></ul><a href="http://keyunluo.github.io/algorithm" title="个人算法练习" target="_blank">个人算法练习</a></div><div class="widget"><div class="widget-title"><i class="fa fa-bar-chart"> 访客</i></div><a href="http://info.flagcounter.com/uNxw"><img src="http://s07.flagcounter.com/count2/uNxw/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_3/labels_0/pageviews_0/flags_0/percent_0/" alt="" border="0"></a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">流光.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=1.0.0"><script>var duoshuoQuery = {short_name:'streamers'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script><script type="text/javascript" src="/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-76470846-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?945b21807344d0260f24455bbd82dfea";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>