<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Coder On The Road"><title>Hadoop源码学习(12)——MapFile | 流光</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.1.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.2/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/2.2.3/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Hadoop源码学习(12)——MapFile</h1><a id="logo" href="/.">流光</a><p class="description">他跑啊跑啊，只为追上那个曾经被寄予厚望的自己</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/guestbook/"><i class="fa fa-comments"> 留言</i></a><a href="/resource/share"><i class="fa fa-download"> 资源</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-4-5"><div class="content_container"><div class="post"><h1 class="post-title">Hadoop源码学习(12)——MapFile</h1><div class="post-meta">Aug 13, 2016<span> | </span><span class="category"><a href="/categories/SourceCodeLearning/">SourceCodeLearning</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-thread-key="2016/08/13/2016-08-13-hadoop-io-8.html" href="/2016/08/13/2016-08-13-hadoop-io-8.html#comments" class="ds-thread-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#MapFile相关类"><span class="toc-number">1.</span> <span class="toc-text">MapFile相关类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapFile写操作"><span class="toc-number">2.</span> <span class="toc-text">MapFile写操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapFile读操作"><span class="toc-number">3.</span> <span class="toc-text">MapFile读操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#将SequenceFile转换成MapFile"><span class="toc-number">4.</span> <span class="toc-text">将SequenceFile转换成MapFile</span></a></li></ol></div></div><div class="post-content"><blockquote>
<p><strong>本节内容：</strong>MapFile是已经排过序的SequenceFile，它有索引，所以可以按键查找。可以将MapFile视为java.util.Map的持久化形式(尽管它并没有实现该接口)，它的大小可以超过保存在内存中一个map的大小。</p>
</blockquote>
<a id="more"></a>
<h2 id="MapFile相关类"><a href="#MapFile相关类" class="headerlink" title="MapFile相关类"></a>MapFile相关类</h2><p>与MapFile相关的类共有3个，它们都位于org.apache.hadoop.io包下：</p>
<ul>
<li>ArrayFile：一种稠密的基于文件的从整数到值的映射。整型表示数组元素的索引，值是Writable类型。</li>
<li>BloomMapFile：使用动态Bloom过滤器来提供快速的键之间的测试，并且提供了一个快速的Reader.get(WritableComparable, Writable)操作，尤其在稀疏密度的MapFile中。该实现使用一个动态的布隆过滤器来检测某个给定的键是否在map文件中，这个操作在内存中实现，故而速度比较快，但可能误判。经过布隆过滤器过滤后，如果存在相应的结果，则调用get()方法。</li>
<li>SetFile：一个基于文件的keys集合。用于存储Writable键的集合，键必须按照排好的顺序添加。</li>
</ul>
<p><img src="/resource/blog/2016-08/MapFile.png" alt="MapFile类"></p>
<h2 id="MapFile写操作"><a href="#MapFile写操作" class="headerlink" title="MapFile写操作"></a>MapFile写操作</h2><p>MapFile的写操作类似于SequenceFile的写操作。新建一个MapFile.Writer实例，然后调用append()方法顺序写入文件内容。如果不按顺序写入，就会抛出一个IOException异常。键必须是WritableComparable类型的实例，值必须是Writable类型的实例，这与SequenceFile正好相反，后者可以为其条目使用任意序列化框架。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.MapFile;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MapFileWriteDemo</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String[] DATA = &#123;</span><br><span class="line">    <span class="string">"One, two, buckle my shoe"</span>,</span><br><span class="line">    <span class="string">"Three, four, shut the door"</span>,</span><br><span class="line">    <span class="string">"Five, six, pick up sticks"</span>,</span><br><span class="line">    <span class="string">"Seven, eight, lay them straight"</span>,</span><br><span class="line">    <span class="string">"Nine, ten, a big fat hen"</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">    String url = args[<span class="number">0</span>];</span><br><span class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    FileSystem fs = FileSystem.get(URI.create(url),conf);</span><br><span class="line"></span><br><span class="line">    IntWritable key = <span class="keyword">new</span> IntWritable();</span><br><span class="line">    Text value = <span class="keyword">new</span> Text();</span><br><span class="line">    MapFile.Writer writer = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">        writer = <span class="keyword">new</span> MapFile.Writer(conf,fs,url,key.getClass(),value.getClass());</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">1024</span>;i++)&#123;</span><br><span class="line">            key.set(i+<span class="number">1</span>);</span><br><span class="line">            value.set(DATA[i % DATA.length]);</span><br><span class="line">            writer.append(key,value);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span>&#123;</span><br><span class="line">        IOUtils.closeStream(writer);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译运行：
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">➜  project export CLASSPATH=$HADOOP_CLASSPATH:$CLASSPATH</span><br><span class="line">➜  project javac MapFileWriteDemo.java</span><br><span class="line">注: MapFileWriteDemo.java使用或覆盖了已过时的 API。</span><br><span class="line">注: 有关详细信息, 请使用 -Xlint:deprecation 重新编译。</span><br><span class="line">➜  project java MapFileWriteDemo  mapfile.map</span><br><span class="line"><span class="number">16</span>/<span class="number">08</span>/<span class="number">13</span> <span class="number">15</span>:<span class="number">07</span>:<span class="number">57</span> WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes where applicable</span><br><span class="line"><span class="number">16</span>/<span class="number">08</span>/<span class="number">13</span> <span class="number">15</span>:<span class="number">07</span>:<span class="number">58</span> INFO compress.CodecPool: Got brand-new compressor [.deflate]</span><br><span class="line"><span class="number">16</span>/<span class="number">08</span>/<span class="number">13</span> <span class="number">15</span>:<span class="number">07</span>:<span class="number">59</span> INFO compress.CodecPool: Got brand-new compressor [.deflate]</span><br><span class="line">➜  project hdfs dfs -ls</span><br><span class="line">Found <span class="number">2</span> items</span><br><span class="line">drwxr-xr-x   - streamer supergroup          <span class="number">0</span> <span class="number">2016</span><span class="number">-05</span><span class="number">-25</span> <span class="number">22</span>:<span class="number">37</span> COPROCESSOR</span><br><span class="line">drwxr-xr-x   - streamer supergroup          <span class="number">0</span> <span class="number">2016</span><span class="number">-08</span><span class="number">-13</span> <span class="number">15</span>:<span class="number">07</span> mapfile.map</span><br><span class="line">➜  project hdfs dfs -text mapfile.map/data | head</span><br><span class="line"><span class="number">16</span>/<span class="number">08</span>/<span class="number">13</span> <span class="number">15</span>:<span class="number">10</span>:<span class="number">20</span> INFO zlib.ZlibFactory: Successfully loaded &amp; initialized native-zlib library</span><br><span class="line"><span class="number">16</span>/<span class="number">08</span>/<span class="number">13</span> <span class="number">15</span>:<span class="number">10</span>:<span class="number">20</span> INFO compress.CodecPool: Got brand-new decompressor [.deflate]</span><br><span class="line"><span class="number">1</span>   One, two, buckle my shoe</span><br><span class="line"><span class="number">2</span>   Three, four, shut the door</span><br><span class="line"><span class="number">3</span>   Five, six, pick up sticks</span><br><span class="line"><span class="number">4</span>   Seven, eight, lay them straight</span><br><span class="line"><span class="number">5</span>   Nine, ten, a big fat hen</span><br><span class="line"><span class="number">6</span>   One, two, buckle my shoe</span><br><span class="line"><span class="number">7</span>   Three, four, shut the door</span><br><span class="line"><span class="number">8</span>   Five, six, pick up sticks</span><br><span class="line"><span class="number">9</span>   Seven, eight, lay them straight</span><br><span class="line"><span class="number">10</span>  Nine, ten, a big fat hen</span><br><span class="line"></span><br><span class="line">➜  project hdfs dfs -text mapfile.map/index</span><br><span class="line"><span class="number">16</span>/<span class="number">08</span>/<span class="number">13</span> <span class="number">15</span>:<span class="number">10</span>:<span class="number">41</span> INFO zlib.ZlibFactory: Successfully loaded &amp; initialized native-zlib library</span><br><span class="line"><span class="number">16</span>/<span class="number">08</span>/<span class="number">13</span> <span class="number">15</span>:<span class="number">10</span>:<span class="number">41</span> INFO compress.CodecPool: Got brand-new decompressor [.deflate]</span><br><span class="line"><span class="number">16</span>/<span class="number">08</span>/<span class="number">13</span> <span class="number">15</span>:<span class="number">10</span>:<span class="number">41</span> INFO compress.CodecPool: Got brand-new decompressor [.deflate]</span><br><span class="line"><span class="number">16</span>/<span class="number">08</span>/<span class="number">13</span> <span class="number">15</span>:<span class="number">10</span>:<span class="number">41</span> INFO compress.CodecPool: Got brand-new decompressor [.deflate]</span><br><span class="line"><span class="number">16</span>/<span class="number">08</span>/<span class="number">13</span> <span class="number">15</span>:<span class="number">10</span>:<span class="number">41</span> INFO compress.CodecPool: Got brand-new decompressor [.deflate]</span><br><span class="line"><span class="number">1</span>   <span class="number">128</span></span><br><span class="line"><span class="number">129</span> <span class="number">6079</span></span><br><span class="line"><span class="number">257</span> <span class="number">12054</span></span><br><span class="line"><span class="number">385</span> <span class="number">18030</span></span><br><span class="line"><span class="number">513</span> <span class="number">24002</span></span><br><span class="line"><span class="number">641</span> <span class="number">29976</span></span><br><span class="line"><span class="number">769</span> <span class="number">35947</span></span><br><span class="line"><span class="number">897</span> <span class="number">41922</span></span><br></pre></td></tr></table></figure></p>
<p>可以发现MapFile包含data和index两个文件，这两个文件都是SequenceFile，data文件包含所有记录，index文件包含一部分键和data文件键到其偏移量的映射。</p>
<p>从输出中可以看见，默认情况下只有每隔128隔键才有一个包含在index文件中，当然也可以调整，调用MapFile.Writer实例的setIndexInterval()方法来设置io.map.index.interval属性即可。增加索引间隔大小可以有效减少MapFile存储索引所需要的内存，但降低了随机访问效率。</p>
<p>因为索引只保留了一部分键，所以整个MapFile无法枚举所有键甚至计算它自己有多少键，唯一的办法是读取整个文件。</p>
<h2 id="MapFile读操作"><a href="#MapFile读操作" class="headerlink" title="MapFile读操作"></a>MapFile读操作</h2><p>在MapFile中依次遍历文件中所有条目的过程类似于SequenceFile中的过程：首先新建一个MapFile.Reader实例，然后调用next()方法，直到返回值为false，表示没有条目返回，因为已经读到文件末尾，通过调用get()方法可以随机访问文件中的数据，返回值用于确定是否在MapFile中找到相应的条目，如果是null，说明指定key没有相应的条目。</p>
<p>getClosest()方法与get()方法类似，只不过它返回的是与指定键匹配的最接近的键，而不是在不匹配时返回null，更准确地说，如果MapFile包含指定的键，则返回对应的条目，否则，返回MapFile中第一个大于(或小于，由相应的boolean参数指定)指定键的键。</p>
<p>大型MapFile的索引会占据大量内存，不要在修改索引间隔之后重建索引，要在读取索引时设置io.mao.index.skip属性来加载一定比例的索引键。该属性通常设置为0，意味着不跳过索引键，如果设置为1，则表示每次跳过索引键中的一个。设置的越大，越节省内存，但会增加搜索时间，因为平均而言，扫描的键更多。</p>
<h2 id="将SequenceFile转换成MapFile"><a href="#将SequenceFile转换成MapFile" class="headerlink" title="将SequenceFile转换成MapFile"></a>将SequenceFile转换成MapFile</h2><p>在MapFile中搜索相当于在加有索引和排过序的SequenceFile中搜索，下面例子显示了对MapFile调用fix()静态方法，将SequenceFile重建索引成MapFile。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.MapFile;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.SequenceFile;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MapFileFixer</span></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">    String url = args[<span class="number">0</span>];</span><br><span class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    FileSystem fs = FileSystem.get(URI.create(url),conf);</span><br><span class="line"></span><br><span class="line">    Path map = <span class="keyword">new</span> Path(url);</span><br><span class="line">    Path mapData = <span class="keyword">new</span> Path(map,MapFile.DATA_FILE_NAME);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 从sequence 数据文件获得key和value的类型</span></span><br><span class="line">    SequenceFile.Reader reader = <span class="keyword">new</span> SequenceFile.Reader(fs,mapData,conf);</span><br><span class="line">    Class keyClass = reader.getKeyClass();</span><br><span class="line">    Class valueClass = reader.getValueClass();</span><br><span class="line">    reader.close();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建map索引文件</span></span><br><span class="line">    <span class="keyword">long</span> entries = MapFile.fix(fs,map,keyClass,valueClass,<span class="keyword">false</span>,conf);</span><br><span class="line">    System.out.printf(<span class="string">"创建MapFile %s ,入口是 %d"</span>,map,entries);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Fix()方法通常用于重建已损坏的索引，但它能够从头开始建立新的索引，所以此处我们可以使用此方法满足需求，具体用法如下：</p>
<p>(1) 将名为 numbers.seq的顺序文件排序后，保存到名为number.map的文件夹下，该文件夹就是最终的MapFile(如果顺序文件已经排过序，则可以跳过这一步。只需要把这个文件复制到number.map/data文件，然后直接跳至第三步)：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar sort -r 1 \</span><br><span class="line">-inFormat org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat \</span><br><span class="line">-outFormat org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat \</span><br><span class="line">-outKey org.apache.hadoop.io.IntWritable \</span><br><span class="line">-outValue org.apache.hadoop.io.Text \</span><br><span class="line">numbers.seq numbers.map</span><br></pre></td></tr></table></figure>
<p>(2) 将MapReduce的输出重命名为data文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mv numbers.map/part-r-00000 numbers.map/data</span><br></pre></td></tr></table></figure>
<p>(3) 建立index文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java MapFileFixer numbers.map</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">➜  project java MapFileFixer numbers.map</span><br><span class="line"><span class="number">16</span>/<span class="number">08</span>/<span class="number">13</span> <span class="number">17</span>:<span class="number">45</span>:<span class="number">39</span> WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes where applicable</span><br><span class="line"><span class="number">16</span>/<span class="number">08</span>/<span class="number">13</span> <span class="number">17</span>:<span class="number">45</span>:<span class="number">40</span> INFO compress.CodecPool: Got brand-new compressor [.deflate]</span><br><span class="line">创建MapFile numbers.map ,入口是 <span class="number">1024</span>%</span><br><span class="line">➜  project hdfs dfs -ls numbers.map</span><br><span class="line">Found <span class="number">2</span> items</span><br><span class="line">-rw-r--r--   <span class="number">1</span> streamer supergroup      <span class="number">40403</span> <span class="number">2016</span><span class="number">-08</span><span class="number">-13</span> <span class="number">17</span>:<span class="number">43</span> numbers.map/data</span><br><span class="line">-rw-r--r--   <span class="number">1</span> streamer supergroup        <span class="number">336</span> <span class="number">2016</span><span class="number">-08</span><span class="number">-13</span> <span class="number">17</span>:<span class="number">45</span> numbers.map/index</span><br></pre></td></tr></table></figure>
<p>大功告成。</p>
</div><script type="text/javascript" src="/js/share.js?v=1.0.0" async></script><a data-url="http://keyunluo.github.io/2016/08/13/2016-08-13-hadoop-io-8.html" data-id="cix1uny6b005ivlglc5qkqzmc" class="article-share-link">分享到</a><div class="tags"><a href="/tags/Hadoop/">Hadoop</a></div><div class="post-nav"><a href="/2016/08/14/2016-08-14-hadoop-io-9.html" class="pre">Hadoop源码学习(13)——压缩(1)</a><a href="/2016/08/13/2016-08-13-hadoop-io-7.html" class="next">Hadoop源码学习(11)——SequenceFile</a></div><div data-thread-key="2016/08/13/2016-08-13-hadoop-io-8.html" data-title="Hadoop源码学习(12)——MapFile" data-url="http://keyunluo.github.io/2016/08/13/2016-08-13-hadoop-io-8.html" class="ds-share flat"><div class="ds-share-inline"><ul class="ds-share-icons-16"><li data-toggle="ds-share-icons-more"><a href="javascript:void(0);" class="ds-more">分享到：</a></li><li><a href="javascript:void(0);" data-service="weibo" class="ds-weibo">微博</a></li><li><a href="javascript:void(0);" data-service="qzone" class="ds-qzone">QQ空间</a></li><li><a href="javascript:void(0);" data-service="qqt" class="ds-qqt">腾讯微博</a></li><li><a href="javascript:void(0);" data-service="wechat" class="ds-wechat">微信</a></li></ul><div class="ds-share-icons-more"></div></div></div><div data-thread-key="2016/08/13/2016-08-13-hadoop-io-8.html" data-title="Hadoop源码学习(12)——MapFile" data-url="http://keyunluo.github.io/2016/08/13/2016-08-13-hadoop-io-8.html" data-author-key="1" class="ds-thread"></div></div></div></div><div class="pure-u-1-5"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/AdvancedAlgorithms/">AdvancedAlgorithms</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/AlgorithmApplication/">AlgorithmApplication</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/BigData/">BigData</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DataBase/">DataBase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DistributedSystem/">DistributedSystem</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/FileAndStorage/">FileAndStorage</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Life/">Life</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MachineLearning/">MachineLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Programming/">Programming</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/SourceCodeLearning/">SourceCodeLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tools/">Tools</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Latex/" style="font-size: 15px;">Latex</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/Oracle/" style="font-size: 15px;">Oracle</a> <a href="/tags/DataBase/" style="font-size: 15px;">DataBase</a> <a href="/tags/sqoop/" style="font-size: 15px;">sqoop</a> <a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/elasticsearch/" style="font-size: 15px;">elasticsearch</a> <a href="/tags/大数据/" style="font-size: 15px;">大数据</a> <a href="/tags/生活/" style="font-size: 15px;">生活</a> <a href="/tags/毕业/" style="font-size: 15px;">毕业</a> <a href="/tags/二次排序/" style="font-size: 15px;">二次排序</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Markdown/" style="font-size: 15px;">Markdown</a> <a href="/tags/VPN/" style="font-size: 15px;">VPN</a> <a href="/tags/UML/" style="font-size: 15px;">UML</a> <a href="/tags/PlantUML/" style="font-size: 15px;">PlantUML</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/Cloudera/" style="font-size: 15px;">Cloudera</a> <a href="/tags/CentOS/" style="font-size: 15px;">CentOS</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/数据压缩/" style="font-size: 15px;">数据压缩</a> <a href="/tags/OpenCV/" style="font-size: 15px;">OpenCV</a> <a href="/tags/LSM树/" style="font-size: 15px;">LSM树</a> <a href="/tags/存储引擎/" style="font-size: 15px;">存储引擎</a> <a href="/tags/分布式系统/" style="font-size: 15px;">分布式系统</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/12/23/2016-12-23-distributed-system-1.html">分布式系统——课程总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/23/2016-12-22-data-mining.html">数据挖掘——课程总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/16/2016-11-16-skiplist1.html">SkipList 跳跃表(1) ——基本介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/16/2016-11-16-lsm1.html">LSM Tree (1)</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/15/2016-11-15-hash.html">Hash存储引擎</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/03/2016-11-03-advanced-algorithm-assignment2.html">高级算法--作业2</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/13/2016-10-13-advanced-algorithm-assignment1.html">高级算法--作业1</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/06/2016-10-06-advanced-algorithm-3.html">高级算法(3)--Min-Cut-Max-Flow(2)-近似算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/05/2016-10-05-advanced-algorithm-2.html">高级算法(2)--Min-Cut-Max-Flow(1)-确定性算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/04/2016-10-04-advanced-algorithm-1.html">高级算法(1)--NP完全性与近似算法</a></li></ul></div><div class="widget"><div class="comments-title"><i class="fa fa-comment-o"> 最近评论</i></div><div data-num-items="5" data-show-avatars="0" data-show-time="1" data-show-admin="0" data-excerpt-length="32" data-show-title="1" class="ds-recent-comments"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 外部链接</i></div><ul></ul><a href="http://keyunluo.github.io/algorithm" title="个人算法练习" target="_blank">个人算法练习</a></div><div class="widget"><div class="widget-title"><i class="fa fa-bar-chart"> 访客</i></div><a href="http://info.flagcounter.com/uNxw"><img src="http://s07.flagcounter.com/count2/uNxw/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_3/labels_0/pageviews_0/flags_0/percent_0/" alt="" border="0"></a></div></div></div><div class="pure-u-1 pure-u-md-4-5"><div id="footer">© <a href="/." rel="nofollow">流光.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=1.0.0"><script>var duoshuoQuery = {short_name:'streamers'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script><script type="text/javascript" src="/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-76470846-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?945b21807344d0260f24455bbd82dfea";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>