<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Coder On The Road"><title>统计学习方法——K近邻算法 | 流光</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.1.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.2/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/2.2.3/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">统计学习方法——K近邻算法</h1><a id="logo" href="/.">流光</a><p class="description">他跑啊跑啊，只为追上那个曾经被寄予厚望的自己</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/guestbook/"><i class="fa fa-comments"> 留言</i></a><a href="/resource/share"><i class="fa fa-download"> 资源</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-4-5"><div class="content_container"><div class="post"><h1 class="post-title">统计学习方法——K近邻算法</h1><div class="post-meta">Aug 15, 2016<span> | </span><span class="category"><a href="/categories/MachineLearning/">MachineLearning</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-thread-key="2016/08/15/2016-08-15-statical-learning-3.html" href="/2016/08/15/2016-08-15-statical-learning-3.html#comments" class="ds-thread-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#K近邻算法"><span class="toc-number">1.</span> <span class="toc-text">K近邻算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#算法描述"><span class="toc-number">1.1.</span> <span class="toc-text">算法描述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#算法流程"><span class="toc-number">1.2.</span> <span class="toc-text">算法流程</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#K近邻模型"><span class="toc-number">2.</span> <span class="toc-text">K近邻模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#模型"><span class="toc-number">2.1.</span> <span class="toc-text">模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#距离度量"><span class="toc-number">2.2.</span> <span class="toc-text">距离度量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#k值的选择"><span class="toc-number">2.3.</span> <span class="toc-text">k值的选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#分类决策规则"><span class="toc-number">2.4.</span> <span class="toc-text">分类决策规则</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kd树"><span class="toc-number">3.</span> <span class="toc-text">kd树</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#构造kd树"><span class="toc-number">3.1.</span> <span class="toc-text">构造kd树</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#算法流程-1"><span class="toc-number">3.1.1.</span> <span class="toc-text">算法流程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#例子"><span class="toc-number">3.1.2.</span> <span class="toc-text">例子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#python实现"><span class="toc-number">3.1.3.</span> <span class="toc-text">python实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#可视化"><span class="toc-number">3.1.4.</span> <span class="toc-text">可视化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#搜索kd树"><span class="toc-number">3.2.</span> <span class="toc-text">搜索kd树</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#算法流程-2"><span class="toc-number">3.2.1.</span> <span class="toc-text">算法流程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#python实现-1"><span class="toc-number">3.2.2.</span> <span class="toc-text">python实现</span></a></li></ol></li></ol></li></ol></div></div><div class="post-content"><blockquote>
<p><strong>本节内容：</strong>k近邻算法(k-nearest neighbor,k-NN)是一种基本的分类与回归算法，不具有显式的学习过程。k值选择、距离度量以及分类决策规则是k近邻算法的三个基本要素。本节对应于统计学习方法第三章的内容。</p>
</blockquote>
<a id="more"></a>
<h2 id="K近邻算法"><a href="#K近邻算法" class="headerlink" title="K近邻算法"></a>K近邻算法</h2><h3 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h3><p>给定一个训练数据集，对新的输入实例，在训练数据集中找到跟它最近的k个实例，根据这k个实例的类判断它自己的类（一般采用多数表决的方法）。</p>
<h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><p>输入： 训练数据集 $T=\{(x_1,y_1),(x_2,y_2),\cdots ,(x_N,y_N)\}$, 其中，$x_i \in \mathcal{X} \subseteq R^n$ 为实例的特征向量，$y_i \in \mathcal{Y} = \{c_1,c_2,\cdots ,c_K \}$为实例的类别，$i = 1,2,\cdots ,N;$实例特征向量$x;$</p>
<p>输出：实例x所属的类别y</p>
<p>(1) 根据给定的距离度量，在训练集T中找出与x最邻近的k个点，涵盖这k个点的x的领域记为$N_k(x)$;</p>
<p>(2) 在$N_k(x)$中根据分类决策规则(如多数表决)决定x的类别y:</p>
<p>$$y = arg max_{c_j} \sum_{x_i \in N_k(x)} I(y_i = c_j),i=1,2, \cdots ,N;j = 1,2, \cdots ,K$$</p>
<p>式中I为指示函数，即当$y_i=c_i$时I为1，否则I为0.</p>
<p>k近邻算法的特殊情况是k=1的情形，称为最近邻算法。对于输入的实例点x，最近邻法将训练数据集中与x最邻近的类作为x的类。</p>
<h2 id="K近邻模型"><a href="#K近邻模型" class="headerlink" title="K近邻模型"></a>K近邻模型</h2><p>模型有3个要素——距离度量方法、k值的选择和分类决策规则。</p>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>当3要素确定的时候，对任何实例（训练或输入），它所属的类都是确定的，相当于将特征空间分为一些子空间。</p>
<p><img src="/resource/blog/2016-08/k近邻模型.jpg" alt="k近邻模型"></p>
<h3 id="距离度量"><a href="#距离度量" class="headerlink" title="距离度量"></a>距离度量</h3><p>对n维实数向量空间$R^n$，经常用$L_p$距离或曼哈顿$Minkowski$距离。</p>
<p>设特征空间$\mathcal{X}$是n维实数向量空间$R^n,x_i,x_j \in \mathcal{X}, x_i = (x_i^{(1)},x_i^{(2)},\cdots , x_i^{(n)})^T,x_j = (x_j^{(1)},x_j^{(2)},\cdots , x_j^{(n)})^T,x_i,x_j的L_p距离定义为：$</p>
<p>$$L_p(x_i,x_j)=\left( \sum_{l=1}^{n} \vert x_i^{(l)}-x_j^{(l)} \vert ^p \right)^{\frac{1}{p}}$$</p>
<p>这里$p \geq 1$,当p=2时，称为欧氏距离(Euclidean distance)，即：</p>
<p>$$L_2(x_i,x_j)=\left( \sum_{l=1}^{n} \vert x_i^{(l)}-x_j^{(l)} \vert ^2 \right ) ^{\frac{1}{2}}$$</p>
<p>当p=1时，称为曼哈顿距离(Manhattan distance),即：</p>
<p>$$L_1(x_i,x_j)=\sum_{l=1}^{n} \vert x_i^{(l)}-x_j^{(l)} \vert $$</p>
<p>当$p=\infty$时，它是各个坐标距离的最大值,即：</p>
<p>$$L_{\infty}(x_i,x_j)=\max \vert x_i^{(l)}-x_j^{(l)} \vert $$</p>
<h3 id="k值的选择"><a href="#k值的选择" class="headerlink" title="k值的选择"></a>k值的选择</h3><p>k较小，容易被噪声影响，发生过拟合。</p>
<p>k较大，较远的训练实例也会对预测起作用，容易发生错误。</p>
<p>在应用中，k值一般取一个比较小的数值，通常采用交叉验证法来选取最优的k值。</p>
<h3 id="分类决策规则"><a href="#分类决策规则" class="headerlink" title="分类决策规则"></a>分类决策规则</h3><p>使用0-1损失函数衡量，那么误分类率是：</p>
<p>$$\frac{1}{k} \sum_{x_i \in N_k(x)} I(y_i \not= c_j) = 1- \frac{1}{k}\sum_{x_i \in N_k(x)} I(y_i = c_j)$$</p>
<p>$N_k$是近邻集合，要使左边最小，右边$\sum_{x_i \in N_k(x)} I(y_i = c_j)$必须最大，所以多数表决等价于经验风险最小化。</p>
<h2 id="kd树"><a href="#kd树" class="headerlink" title="kd树"></a>kd树</h2><p>算法核心在于怎么快速搜索k个近邻出来，朴素做法是线性扫描，不可取，这里介绍的方法是kd树。</p>
<h3 id="构造kd树"><a href="#构造kd树" class="headerlink" title="构造kd树"></a>构造kd树</h3><p>对数据集T中的子集S初始化S=T，取当前节点node=root取维数的序数i=0，对S递归执行：</p>
<p>找出S的第i维的中位数对应的点，通过该点，且垂直于第i维坐标轴做一个超平面。该点加入node的子节点。该超平面将空间分为两个部分，对这两个部分分别重复此操作（S=S’，++i，node=current），直到不可再分。</p>
<h4 id="算法流程-1"><a href="#算法流程-1" class="headerlink" title="算法流程"></a>算法流程</h4><p>输入：k维空间数据集 $T=\{x_1,x_2,…,x_N\}$,其中$x_i=(x_i^{(1)},x_i^{(2)},\cdots ,x_i^{(k)})^T,i=1,2,\cdots ,N$</p>
<p>输出： kd树</p>
<p>(1) 开始：构造根节点，根节点对应于包含T的k维空间的超矩形区域：选择$x^{(1)}$为坐标轴，以T中所有实例的$x^{(1)}$坐标的中位数为切分点，将根节点对应的超矩形区域切分为两个子区域。切分由通过切分点并与坐标轴$x^{(1)}$垂直的超平面实现。</p>
<p>由根节点生成深度为1的左右子节点：左子节点对应坐标$x^{(1)}$小于切分点的子区域，右子节点对应坐标$x^{(1)}$大于切分点的子区域。</p>
<p>将落在切分超平面的实例点保存在根节点。</p>
<p>(2) 重复：对深度为j的节点，选择$x^{(l)}$为切分的坐标轴，$l=j(mod k) +1$,以该节点的区域中所有实例的$x^{(l)}$坐标的中位数为切分点，将该节点对应的超矩形区域切分为两个子区域，切分由通过切分点并与坐标轴$x^{(l)}$垂直的超平面实现。</p>
<p>由该节点生成深度为j+1的左右子节点：左子节点对应坐标$x^{(l)}$小于切分点的子区域，右子节点对应坐标$x^{(l)}$大于切分点的子区域。</p>
<p>将落在切分超平面的实例点保存在根节点。</p>
<p>(3) 直到两个子区域没有实例存在时停止，从而形成kd树的区域划分。</p>
<h4 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h4><p>给定一个二维空间的数据集：$T=\{(2,3)^T,(5,4)^T,(9,6)^T,(4,7)^T,(8,1)^T,(7,2)^T\}$,
构造一棵平衡kd树。</p>
<h4 id="python实现"><a href="#python实现" class="headerlink" title="python实现"></a>python实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">T = [[<span class="number">2</span>, <span class="number">3</span>], [<span class="number">5</span>, <span class="number">4</span>], [<span class="number">9</span>, <span class="number">6</span>], [<span class="number">4</span>, <span class="number">7</span>], [<span class="number">8</span>, <span class="number">1</span>], [<span class="number">7</span>, <span class="number">2</span>]]</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">node</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, point)</span>:</span></span><br><span class="line">        self.left = <span class="keyword">None</span></span><br><span class="line">        self.right = <span class="keyword">None</span></span><br><span class="line">        self.point = point</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">median</span><span class="params">(lst)</span>:</span></span><br><span class="line">    m = int(len(lst) / <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> lst[m], m</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_kdtree</span><span class="params">(data, d)</span>:</span></span><br><span class="line">    data = sorted(data, key=<span class="keyword">lambda</span> x: x[d])</span><br><span class="line">    p, m = median(data)</span><br><span class="line">    tree = node(p)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">del</span> data[m]</span><br><span class="line">    print(data, p)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> m &gt; <span class="number">0</span>: tree.left = build_kdtree(data[:m], <span class="keyword">not</span> d)</span><br><span class="line">    <span class="keyword">if</span> len(data) &gt; <span class="number">1</span>: tree.right = build_kdtree(data[m:], <span class="keyword">not</span> d)</span><br><span class="line">    <span class="keyword">return</span> tree</span><br><span class="line"></span><br><span class="line">kd_tree = build_kdtree(T, <span class="number">0</span>)</span><br><span class="line">print(kd_tree)</span><br></pre></td></tr></table></figure>
<h4 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># Filename: kdtree.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.patches <span class="keyword">import</span> Rectangle</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> animation</span><br><span class="line"></span><br><span class="line">T = [[<span class="number">2</span>, <span class="number">3</span>], [<span class="number">5</span>, <span class="number">4</span>], [<span class="number">9</span>, <span class="number">6</span>], [<span class="number">4</span>, <span class="number">7</span>], [<span class="number">8</span>, <span class="number">1</span>], [<span class="number">7</span>, <span class="number">2</span>]]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_point</span><span class="params">(data)</span>:</span></span><br><span class="line">    X, Y = [], []</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> data:</span><br><span class="line">        X.append(p[<span class="number">0</span>])</span><br><span class="line">        Y.append(p[<span class="number">1</span>])</span><br><span class="line">    plt.plot(X, Y, <span class="string">'bo'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_line</span><span class="params">(xy_list)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> xy <span class="keyword">in</span> xy_list:</span><br><span class="line">        x, y = xy</span><br><span class="line">        plt.plot(x, y, <span class="string">'g'</span>, lw=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_square</span><span class="params">(square_list)</span>:</span></span><br><span class="line">    currentAxis = plt.gca()</span><br><span class="line">    colors = itertools.cycle([<span class="string">"r"</span>, <span class="string">"b"</span>, <span class="string">"g"</span>, <span class="string">"c"</span>, <span class="string">"m"</span>, <span class="string">"y"</span>, <span class="string">'#EB70AA'</span>, <span class="string">'#0099FF'</span>])</span><br><span class="line">    <span class="keyword">for</span> square <span class="keyword">in</span> square_list:</span><br><span class="line">        currentAxis.add_patch(</span><br><span class="line">            Rectangle((square[<span class="number">0</span>][<span class="number">0</span>], square[<span class="number">0</span>][<span class="number">1</span>]), square[<span class="number">1</span>][<span class="number">0</span>] - square[<span class="number">0</span>][<span class="number">0</span>], square[<span class="number">1</span>][<span class="number">1</span>] - square[<span class="number">0</span>][<span class="number">1</span>],</span><br><span class="line">                      color=next(colors)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">median</span><span class="params">(lst)</span>:</span></span><br><span class="line">    m = int(len(lst) / <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> lst[m], m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">history_quare = []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_kdtree</span><span class="params">(data, d, square)</span>:</span></span><br><span class="line">    history_quare.append(square)</span><br><span class="line">    data = sorted(data, key=<span class="keyword">lambda</span> x: x[d])</span><br><span class="line">    p, m = median(data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">del</span> data[m]</span><br><span class="line">    print(data, p)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> m &gt;= <span class="number">0</span>:</span><br><span class="line">        sub_square = copy.deepcopy(square)</span><br><span class="line">        <span class="keyword">if</span> d == <span class="number">0</span>:</span><br><span class="line">            sub_square[<span class="number">1</span>][<span class="number">0</span>] = p[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            sub_square[<span class="number">1</span>][<span class="number">1</span>] = p[<span class="number">1</span>]</span><br><span class="line">        history_quare.append(sub_square)</span><br><span class="line">        <span class="keyword">if</span> m &gt; <span class="number">0</span>: build_kdtree(data[:m], <span class="keyword">not</span> d, sub_square)</span><br><span class="line">    <span class="keyword">if</span> len(data) &gt; <span class="number">1</span>:</span><br><span class="line">        sub_square = copy.deepcopy(square)</span><br><span class="line">        <span class="keyword">if</span> d == <span class="number">0</span>:</span><br><span class="line">            sub_square[<span class="number">0</span>][<span class="number">0</span>] = p[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            sub_square[<span class="number">0</span>][<span class="number">1</span>] = p[<span class="number">1</span>]</span><br><span class="line">        build_kdtree(data[m:], <span class="keyword">not</span> d, sub_square)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">build_kdtree(T, <span class="number">0</span>, [[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">10</span>, <span class="number">10</span>]])</span><br><span class="line">print(history_quare)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># draw an animation to show how it works, the data comes from history</span></span><br><span class="line"><span class="comment"># first set up the figure, the axis, and the plot element we want to animate</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = plt.axes(xlim=(<span class="number">0</span>, <span class="number">2</span>), ylim=(<span class="number">-2</span>, <span class="number">2</span>))</span><br><span class="line">line, = ax.plot([], [], <span class="string">'g'</span>, lw=<span class="number">2</span>)</span><br><span class="line">label = ax.text([], [], <span class="string">''</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># initialization function: plot the background of each frame</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init</span><span class="params">()</span>:</span></span><br><span class="line">    plt.axis([<span class="number">0</span>, <span class="number">10</span>, <span class="number">0</span>, <span class="number">10</span>])</span><br><span class="line">    plt.grid(<span class="keyword">True</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'x_1'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'x_2'</span>)</span><br><span class="line">    plt.title(<span class="string">'构造KD树'</span>)</span><br><span class="line">    draw_point(T)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">currentAxis = plt.gca()</span><br><span class="line">colors = itertools.cycle([<span class="string">"#FF6633"</span>, <span class="string">"g"</span>, <span class="string">"#3366FF"</span>, <span class="string">"c"</span>, <span class="string">"m"</span>, <span class="string">"y"</span>, <span class="string">'#EB70AA'</span>, <span class="string">'#0099FF'</span>, <span class="string">'#66FFFF'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># animation function.  this is called sequentially</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">animate</span><span class="params">(i)</span>:</span></span><br><span class="line">    square = history_quare[i]</span><br><span class="line">    currentAxis.add_patch(</span><br><span class="line">        Rectangle((square[<span class="number">0</span>][<span class="number">0</span>], square[<span class="number">0</span>][<span class="number">1</span>]), square[<span class="number">1</span>][<span class="number">0</span>] - square[<span class="number">0</span>][<span class="number">0</span>], square[<span class="number">1</span>][<span class="number">1</span>] - square[<span class="number">0</span>][<span class="number">1</span>],</span><br><span class="line">                  color=next(colors)))</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># call the animator.  blit=true means only re-draw the parts that have changed.</span></span><br><span class="line">anim = animation.FuncAnimation(fig, animate, init_func=init, frames=len(history_quare), interval=<span class="number">1000</span>, repeat=<span class="keyword">False</span>,</span><br><span class="line">                               blit=<span class="keyword">False</span>)</span><br><span class="line">plt.show()</span><br><span class="line">anim.save(<span class="string">'kdtree_build.gif'</span>, fps=<span class="number">2</span>, writer=<span class="string">'imagemagick'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/resource/blog/2016-08/kdtree_build.gif" alt="构建kd树"></p>
<h3 id="搜索kd树"><a href="#搜索kd树" class="headerlink" title="搜索kd树"></a>搜索kd树</h3><h4 id="算法流程-2"><a href="#算法流程-2" class="headerlink" title="算法流程"></a>算法流程</h4><p>搜索跟二叉树一样，是一个递归的过程。先找到目标点的插入位置，然后往上走，逐步用自己到目标点的距离画个超球体，用超球体圈住的点来更新最近邻（或k最近邻）。</p>
<p>输入：已构造的kd树，目标点x</p>
<p>输出：x的最近邻</p>
<p>(1) 在kd树中找到包含目标点x的叶节点：从根节点出发，递归的向下访问kd树。若目标点x当前维的坐标小于切分点的坐标，则移动到左子节点，否则移动到右子节点。直到子节点为叶节点为止。</p>
<p>(2) 以此叶节点为“当前最近点”</p>
<p>(3) 递归的向上回退，在每个节点进行如下操作：</p>
<ul>
<li>如果该节点保存的实例点比当前最近点距离目标点更近，则以该实例点为“当前最近点”</li>
<li>当前最近点一定存在于该节点一个子节点对应的区域，检查该子节点的父节点的另一子节点对应的区域是否有更近的点。具体的，检查另一子节点对应的区域是否以目标点为球心、以目标点与“当前最近点”间的距离为半径的超球体相交。如果相交，可能在另一个子节点对应的区域内存在距离目标点更近的点，移动到另一个子节点，接着，递归地进行最近邻搜索。如果不相交，向上回退</li>
</ul>
<p>(4) 当回退到根节点时，搜索结束。最后的“当前最近点”即为x的最近邻点。</p>
<h4 id="python实现-1"><a href="#python实现-1" class="headerlink" title="python实现"></a>python实现</h4><p>以最近邻为例，实现如下（本实现由于测试数据简单，没有做超球体与超立体相交的逻辑）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># Filename: search_kdtree.py</span></span><br><span class="line"></span><br><span class="line">T = [[<span class="number">2</span>, <span class="number">3</span>], [<span class="number">5</span>, <span class="number">4</span>], [<span class="number">9</span>, <span class="number">6</span>], [<span class="number">4</span>, <span class="number">7</span>], [<span class="number">8</span>, <span class="number">1</span>], [<span class="number">7</span>, <span class="number">2</span>]]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">node</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, point)</span>:</span></span><br><span class="line">        self.left = <span class="keyword">None</span></span><br><span class="line">        self.right = <span class="keyword">None</span></span><br><span class="line">        self.point = point</span><br><span class="line">        self.parent = <span class="keyword">None</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_left</span><span class="params">(self, left)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> left == <span class="keyword">None</span>: <span class="keyword">pass</span></span><br><span class="line">        left.parent = self</span><br><span class="line">        self.left = left</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_right</span><span class="params">(self, right)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> right == <span class="keyword">None</span>: <span class="keyword">pass</span></span><br><span class="line">        right.parent = self</span><br><span class="line">        self.right = right</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">median</span><span class="params">(lst)</span>:</span></span><br><span class="line">    m = int(len(lst) / <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> lst[m], m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_kdtree</span><span class="params">(data, d)</span>:</span></span><br><span class="line">    data = sorted(data, key=<span class="keyword">lambda</span> x: x[d])</span><br><span class="line">    p, m = median(data)</span><br><span class="line">    tree = node(p)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">del</span> data[m]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> m &gt; <span class="number">0</span>: tree.set_left(build_kdtree(data[:m], <span class="keyword">not</span> d))</span><br><span class="line">    <span class="keyword">if</span> len(data) &gt; <span class="number">1</span>: tree.set_right(build_kdtree(data[m:], <span class="keyword">not</span> d))</span><br><span class="line">    <span class="keyword">return</span> tree</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distance</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    print(a, b)</span><br><span class="line">    <span class="keyword">return</span> ((a[<span class="number">0</span>] - b[<span class="number">0</span>]) ** <span class="number">2</span> + (a[<span class="number">1</span>] - b[<span class="number">1</span>]) ** <span class="number">2</span>) ** <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">search_kdtree</span><span class="params">(tree, d, target)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> target[d] &lt; tree.point[d]:</span><br><span class="line">        <span class="keyword">if</span> tree.left != <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> search_kdtree(tree.left, <span class="keyword">not</span> d, target)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> tree.right != <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> search_kdtree(tree.right, <span class="keyword">not</span> d, target)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_best</span><span class="params">(t, best)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> t == <span class="keyword">None</span>: <span class="keyword">return</span></span><br><span class="line">        t = t.point</span><br><span class="line">        d = distance(t, target)</span><br><span class="line">        <span class="keyword">if</span> d &lt; best[<span class="number">1</span>]:</span><br><span class="line">            best[<span class="number">1</span>] = d</span><br><span class="line">            best[<span class="number">0</span>] = t</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    best = [tree.point, <span class="number">100000.0</span>]</span><br><span class="line">    <span class="keyword">while</span> (tree.parent != <span class="keyword">None</span>):</span><br><span class="line">        update_best(tree.parent.left, best)</span><br><span class="line">        update_best(tree.parent.right, best)</span><br><span class="line">        tree = tree.parent</span><br><span class="line">    <span class="keyword">return</span> best[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kd_tree = build_kdtree(T, <span class="number">0</span>)</span><br><span class="line">print(search_kdtree(kd_tree, <span class="number">0</span>, [<span class="number">9</span>, <span class="number">4</span>]))</span><br></pre></td></tr></table></figure>
<p>输出
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">8</span>, <span class="number">1</span>] [<span class="number">9</span>, <span class="number">4</span>]</span><br><span class="line">[<span class="number">5</span>, <span class="number">4</span>] [<span class="number">9</span>, <span class="number">4</span>]</span><br><span class="line">[<span class="number">9</span>, <span class="number">6</span>] [<span class="number">9</span>, <span class="number">4</span>]</span><br><span class="line">[<span class="number">9</span>, <span class="number">6</span>]</span><br></pre></td></tr></table></figure></p>
</div><script type="text/javascript" src="/js/share.js?v=1.0.0" async></script><a data-url="http://keyunluo.github.io/2016/08/15/2016-08-15-statical-learning-3.html" data-id="cix8eoqys003y2bglh4n8ueqd" class="article-share-link">分享到</a><div class="tags"><a href="/tags/机器学习/">机器学习</a></div><div class="post-nav"><a href="/2016/08/16/2016-08-16-statical-learning-4.html" class="pre">统计学习方法——朴素贝叶斯法</a><a href="/2016/08/15/2016-08-15-hadoop-io-10.html" class="next">Hadoop源码学习(14)——压缩(2)</a></div><div data-thread-key="2016/08/15/2016-08-15-statical-learning-3.html" data-title="统计学习方法——K近邻算法" data-url="http://keyunluo.github.io/2016/08/15/2016-08-15-statical-learning-3.html" class="ds-share flat"><div class="ds-share-inline"><ul class="ds-share-icons-16"><li data-toggle="ds-share-icons-more"><a href="javascript:void(0);" class="ds-more">分享到：</a></li><li><a href="javascript:void(0);" data-service="weibo" class="ds-weibo">微博</a></li><li><a href="javascript:void(0);" data-service="qzone" class="ds-qzone">QQ空间</a></li><li><a href="javascript:void(0);" data-service="qqt" class="ds-qqt">腾讯微博</a></li><li><a href="javascript:void(0);" data-service="wechat" class="ds-wechat">微信</a></li></ul><div class="ds-share-icons-more"></div></div></div><div data-thread-key="2016/08/15/2016-08-15-statical-learning-3.html" data-title="统计学习方法——K近邻算法" data-url="http://keyunluo.github.io/2016/08/15/2016-08-15-statical-learning-3.html" data-author-key="1" class="ds-thread"></div></div></div></div><div class="pure-u-1-5"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/AdvancedAlgorithms/">AdvancedAlgorithms</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/AlgorithmApplication/">AlgorithmApplication</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/BigData/">BigData</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DataBase/">DataBase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DistributedSystem/">DistributedSystem</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/FileAndStorage/">FileAndStorage</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Life/">Life</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MachineLearning/">MachineLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Programming/">Programming</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/SourceCodeLearning/">SourceCodeLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tools/">Tools</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Latex/" style="font-size: 15px;">Latex</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/二次排序/" style="font-size: 15px;">二次排序</a> <a href="/tags/VPN/" style="font-size: 15px;">VPN</a> <a href="/tags/Oracle/" style="font-size: 15px;">Oracle</a> <a href="/tags/DataBase/" style="font-size: 15px;">DataBase</a> <a href="/tags/sqoop/" style="font-size: 15px;">sqoop</a> <a href="/tags/elasticsearch/" style="font-size: 15px;">elasticsearch</a> <a href="/tags/大数据/" style="font-size: 15px;">大数据</a> <a href="/tags/生活/" style="font-size: 15px;">生活</a> <a href="/tags/毕业/" style="font-size: 15px;">毕业</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Markdown/" style="font-size: 15px;">Markdown</a> <a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/PlantUML/" style="font-size: 15px;">PlantUML</a> <a href="/tags/UML/" style="font-size: 15px;">UML</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/CentOS/" style="font-size: 15px;">CentOS</a> <a href="/tags/Cloudera/" style="font-size: 15px;">Cloudera</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/数据压缩/" style="font-size: 15px;">数据压缩</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/OpenCV/" style="font-size: 15px;">OpenCV</a> <a href="/tags/存储引擎/" style="font-size: 15px;">存储引擎</a> <a href="/tags/LSM树/" style="font-size: 15px;">LSM树</a> <a href="/tags/分布式系统/" style="font-size: 15px;">分布式系统</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/12/27/2016-12-27-data-mining.html">数据挖掘——试卷分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/23/2016-12-23-distributed-system-1.html">分布式系统——课程总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/22/2016-12-22-data-mining.html">数据挖掘——课程总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/16/2016-11-16-skiplist1.html">SkipList 跳跃表(1) ——基本介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/16/2016-11-16-lsm1.html">LSM Tree (1)</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/15/2016-11-15-hash.html">Hash存储引擎</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/03/2016-11-03-advanced-algorithm-assignment2.html">高级算法--作业2</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/13/2016-10-13-advanced-algorithm-assignment1.html">高级算法--作业1</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/06/2016-10-06-advanced-algorithm-3.html">高级算法(3)--Min-Cut-Max-Flow(2)-近似算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/05/2016-10-05-advanced-algorithm-2.html">高级算法(2)--Min-Cut-Max-Flow(1)-确定性算法</a></li></ul></div><div class="widget"><div class="comments-title"><i class="fa fa-comment-o"> 最近评论</i></div><div data-num-items="5" data-show-avatars="0" data-show-time="1" data-show-admin="0" data-excerpt-length="32" data-show-title="1" class="ds-recent-comments"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 外部链接</i></div><ul></ul><a href="http://keyunluo.github.io/algorithm" title="个人算法练习" target="_blank">个人算法练习</a></div><div class="widget"><div class="widget-title"><i class="fa fa-bar-chart"> 访客</i></div><a href="http://info.flagcounter.com/uNxw"><img src="http://s07.flagcounter.com/count2/uNxw/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_3/labels_0/pageviews_0/flags_0/percent_0/" alt="" border="0"></a></div></div></div><div class="pure-u-1 pure-u-md-4-5"><div id="footer">© <a href="/." rel="nofollow">流光.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=1.0.0"><script>var duoshuoQuery = {short_name:'streamers'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script><script type="text/javascript" src="/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-76470846-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?945b21807344d0260f24455bbd82dfea";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><div id="script" type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></div><script type="text/javascript" src="/js/mathjax/2.7-latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>