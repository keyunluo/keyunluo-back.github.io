<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Coder On The Road"><title>统计学习方法——朴素贝叶斯法 | 流光</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.1.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.2/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/2.2.3/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">统计学习方法——朴素贝叶斯法</h1><a id="logo" href="/.">流光</a><p class="description">他跑啊跑啊，只为追上那个曾经被寄予厚望的自己</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/guestbook/"><i class="fa fa-comments"> 留言</i></a><a href="/resource/share"><i class="fa fa-download"> 资源</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">统计学习方法——朴素贝叶斯法</h1><div class="post-meta">Aug 16, 2016<span> | </span><span class="category"><a href="/categories/MachineLearning/">MachineLearning</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-thread-key="2016/08/16/2016-08-16-statical-learning-4.html" href="/2016/08/16/2016-08-16-statical-learning-4.html#comments" class="ds-thread-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#朴素贝叶斯法的学习与分类"><span class="toc-number">1.</span> <span class="toc-text">朴素贝叶斯法的学习与分类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#基本方法"><span class="toc-number">1.1.</span> <span class="toc-text">基本方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#后验概率最大化的含义"><span class="toc-number">1.2.</span> <span class="toc-text">后验概率最大化的含义</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#朴素贝叶斯法的参数估计"><span class="toc-number">2.</span> <span class="toc-text">朴素贝叶斯法的参数估计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#极大似然估计"><span class="toc-number">2.1.</span> <span class="toc-text">极大似然估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#学习与分类方法"><span class="toc-number">2.2.</span> <span class="toc-text">学习与分类方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#例子"><span class="toc-number">2.3.</span> <span class="toc-text">例子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#贝叶斯估计"><span class="toc-number">2.4.</span> <span class="toc-text">贝叶斯估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#综合：python实现简单情感极性分析器"><span class="toc-number">2.5.</span> <span class="toc-text">综合：python实现简单情感极性分析器</span></a></li></ol></li></ol></div></div><div class="post-content"><blockquote>
<p><strong>本节内容：</strong>朴素贝叶斯(native Bates)是基于贝叶斯定理与特征条件独立假设的分类法。对于给定的训练数据集，首先基于特征条件独立假设学习输入/输出的联合概率密度；然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率的最大的输出y。朴素贝叶斯实现简单，学习和预测的效率都很高，是一种常用的方法。本节对应于统计学习方法第四章的内容。</p>
</blockquote>
<a id="more"></a>
<h2 id="朴素贝叶斯法的学习与分类"><a href="#朴素贝叶斯法的学习与分类" class="headerlink" title="朴素贝叶斯法的学习与分类"></a>朴素贝叶斯法的学习与分类</h2><h3 id="基本方法"><a href="#基本方法" class="headerlink" title="基本方法"></a>基本方法</h3><p>设输入空间$\mathcal{X} \subseteq R^n$为n维向量的集合，输出空间为类标记集合$\mathcal{Y} = \{c_1,c_2, \cdots ,c_K \}$.输入为特征向量$x \in \mathcal{X}$,输出为类标记$y \in \mathcal{Y},X$是定义在输入空间$\mathcal{X}$上的随机变量，$\mathcal{Y}$是定义在输出空间Y上的随机变量.P(X,Y)是X和Y的联合概率分布。训练数据集：</p>
<p>$$T = \{(x_1,y_1),(x_2,y_2), \cdots , (x_N,y_N) \}$$</p>
<p>由P(X,Y)独立同分布产生。朴素贝叶斯法通过训练数据集学习联合概率分布P(X,Y),具体地，学习以下先验概率密度及条件概率密度。先验概率密度：</p>
<p>$$P(Y=c_k) , k= 1,2, \cdots ,K$$</p>
<p>条件概率密度：</p>
<p>$$P(X=x|Y=c_k) = P(X^{(1)}=x^{(1)},\cdots , X^{(n)}=x^{(n)} |Y=c_k), k= 1,2, \cdots ,K$$</p>
<p>于是学习到联合概率分布P(X,Y).</p>
<p>朴素贝叶斯法对条件概率分布作了条件独立性的假设：</p>
<p>$$P(X=x|Y=c_k) = P(X^{(1)}=x^{(1)},\cdots , X^{(n)}=x^{(n)} |Y=c_k)=\prod_{j=1}^n P(X^{(j)}=x^{(j)} | Y = c_k)$$</p>
<p>朴素贝叶斯法实际上学习到的是生成数据的机制，所以属于生成模型。条件独立性假设是说用于分类的特征在类确定的情况都是条件独立的，这一假设会使得朴素贝叶斯法变得简单，但有时会牺牲一定的分类准确率。</p>
<p>朴素贝叶斯法时，对给定的输入x，通过学习到的模型计算后验概率分布$P(Y=c_k|X=x)$，将后验概率最大的类作为x的类输出，后验概率计算根据贝叶斯定理进行：</p>
<p>$$P(Y=c_k|X=x)= \frac{P(X=x|Y=c_k)P(Y=c_k)}{\sum_k P(X=x|Y=c_k)P(Y=c_k)}$$</p>
<p>将条件独立性假设公式带入上式，得：</p>
<p>$$P(Y=c_k|X=x)= \frac{P(Y=c_k)\prod_jP(X^{(j)}=x^{(j)}|Y=c_k)}{\sum_k P(Y=c_k)\prod_jP(X^{(j)}=x^{(j)}s|Y=c_k)} , k=1,2, \cdots ,K$$</p>
<p>考虑到分母对所有的$c_k$都相同，朴素贝叶斯分类器可表示为：</p>
<p>$$y =  arg \max_{c_k}P(Y=c_k)\prod_jP(X^{(j)}=x^{(j)}|Y=c_k)$$</p>
<h3 id="后验概率最大化的含义"><a href="#后验概率最大化的含义" class="headerlink" title="后验概率最大化的含义"></a>后验概率最大化的含义</h3><p>朴素贝叶斯法将实例分到后验概率最大的类中，这等价于期望风险最小化，假设选择0-1损失函数：</p>
<p>$$
L(Y,f(X))=
\begin{cases}
0&amp; Y=f(x)\\
1&amp; Y \neq f(X)
\end{cases}
$$</p>
<p>式中f(X)是分类决策函数，这时期望风险函数为：</p>
<p>$$R_{exp}(f)=E[L(Y,f(X))]$$</p>
<p>期望是对联合分布P(X,Y)取的，由此取期望：</p>
<p>$$R_{exp}(f)=E_X\sum_{k=1}^{K}[L(c_k,f(X))]P(c_k|X)$$</p>
<p>为了使期望风险最小化，只需对X=x逐个最小化，由此得到：</p>
<p>$$f(x)= \arg \min_{y \in \mathcal{Y}} P(y=c_k|X=x)$$</p>
<h2 id="朴素贝叶斯法的参数估计"><a href="#朴素贝叶斯法的参数估计" class="headerlink" title="朴素贝叶斯法的参数估计"></a>朴素贝叶斯法的参数估计</h2><h3 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h3><p>在朴素贝叶斯法中，学习意味着估计$P(Y=c_k)和P(X^{(j)}=x^{(j)}| Y=c_k)$,可以应用极大似然估计法估计相应的概率。先验概率$P(Y=c_k)$的极大似然估计是：</p>
<p>$$P(Y=c_k)=\frac{\sum_{i=1}^NI(y_i=c_k)}{N},k=1,2,\cdots ,K$$</p>
<p>设第j个特征$x^{(j)}$可能取值的集合为$\{a_{j1},a_{j2},\cdots ,a_{jS_j}\}$,条件概率$P(X^{(j)}=a_{jl}|Y=c_k)$的极大似然估计是：</p>
<p>$$P(X^{(j)}=a_{jl}|Y=c_k)=\frac{\sum_{i=1}^NI(x_i^{(j)}=a_{jl},y_i=c_k)}{\sum_{i=1}^NI(y_i=c_k)}, j=1,2,\cdots ,n;l=1,2,\cdots ,S_j;k=1,2,\cdots ,K$$</p>
<p>式中，$x_i^{(j)}$是第i个样本的第j个特征；$a_{jl}$是第j个特征可能取的第l个值；I为指示函数。</p>
<h3 id="学习与分类方法"><a href="#学习与分类方法" class="headerlink" title="学习与分类方法"></a>学习与分类方法</h3><p><strong>朴素贝叶斯算法</strong></p>
<p>输入：训练数据集$T=\{(x_1,y_1),(x_2,y_2),\cdots ,(x_N,y_N)\}$,其中$x_i=(x_i^{(1)},\cdots , x_i^{(n)})^T,x_i^{(j)}$是第i个样本的第j个特征，$x_i^{(j)} \in \{a_{j1},a_{j2}, \cdots ,a_{jS_j}\},a_{jl}$是第j个特征可能取的第l个值，$j=1,2,\cdots ,n;l=1,2, \cdots ,S_j;y_i \in \{c_1,c_2,\cdots ,c_K\}$;实例x;
输出：实例x的分类</p>
<p>(1) 计算先验概率及条件概率</p>
<p>$$P(Y=c_k)=\frac{\sum_{i=1}^NI(y_i=c_k)}{N},k=1,2,\cdots ,K$$</p>
<p>$$P(X^{(j)}=a_{jl} | Y= c_k)=\frac{\sum_{i=1}^NY(x_i^{(j)}=a_{jl},y_i=c_k)}{\sum_{i=1}^NI(y_i=c_k)},j=1,2,\cdots,n;l=1,2,\cdots,S_j;k=1,2,\cdots,K$$</p>
<p>(2) 对于给定的实例$x=(x^{(1)},x^{(2)},\cdots ,x^{(n)})^T$,计算：</p>
<p>$$P(Y=c_k)\prod_jP(X^{(j)}=x^{(j)}s|Y=c_k) , k=1,2, \cdots ,K$$</p>
<p>(3) 确定实例x的分类</p>
<p>$$y =  arg \max_{c_k}P(Y=c_k)\prod_jP(X^{(j)}=x^{(j)}|Y=c_k)$$</p>
<h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p>试由下表的训练数据学习一个朴素贝叶斯分类器并确定$x=(2,S)^T$的类标记y，表中$X^{(1)},X^{(2)}$为特征，取值的集合分别为$A_1=\{1,2,3\},A_2=\{S,M,L\}$,Y为类标记，$Y \in C =\{1,-1\}$</p>
<table>
<thead>
<tr>
<th></th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
<th>11</th>
<th>12</th>
<th>13</th>
<th>14</th>
<th>15</th>
</tr>
</thead>
<tbody>
<tr>
<td>$X^{(1)}$</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>3</td>
<td>3</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>$X^{(2)}$</td>
<td>S</td>
<td>M</td>
<td>M</td>
<td>S</td>
<td>S</td>
<td>S</td>
<td>M</td>
<td>M</td>
<td>L</td>
<td>L</td>
<td>L</td>
<td>M</td>
<td>M</td>
<td>L</td>
<td>L</td>
</tr>
<tr>
<td>$Y$</td>
<td>-1</td>
<td>-1</td>
<td>1</td>
<td>1</td>
<td>-1</td>
<td>-1</td>
<td>-1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>-1</td>
</tr>
</tbody>
</table>
<p>根据朴素贝叶斯分类器，容易计算下列概率：</p>
<p>$P(Y=1)=9/15,p(Y=-1)=6/15$</p>
<p>$P(X^{(1)}=1|Y=1)=2/9,P(X^{(1)}=2|Y=1)=3/9,P(X^{(1)}=3|Y=1)=4/9$</p>
<p>$P(X^{(2)}=S|Y=1)=1/9,P(X^{(2)}=M|Y=1)=4/9,P(X^{(2)}=L|Y=1)=4/9$</p>
<p>$P(X^{(1)}=1|Y=-1)=3/6,P(X^{(1)}=2|Y=-1)=2/6,P(X^{(1)}=3|Y=-1)=1/6$</p>
<p>$P(X^{(2)}=S|Y=-1)=3/6,P(X^{(2)}=M|Y=-1)=2/6,P(X^{(2)}=L|Y=-1)=1/6$</p>
<p>于是，对于给定的$x=(2,S)^T$,计算：</p>
<p>$P(Y=1)P(X^{(1)}=2|Y=1)P(X^{(2)}=S|Y=1)=9/15\cdot 3/9 \cdot 1/9=1/45$</p>
<p>$P(Y=-1)P(X^{(1)}=2|Y=-1)P(X^{(2)}=S|Y=-1)=6/15\cdot 2/6 \cdot 3/6=1/15$</p>
<p>故$y=-1$</p>
<h3 id="贝叶斯估计"><a href="#贝叶斯估计" class="headerlink" title="贝叶斯估计"></a>贝叶斯估计</h3><p>用极大似然估计可能会出现所要估计的概率的值为0的情况，这时会影响到后验概率的计算结果，使分类出现偏差，解决这一问题的方法是采用贝叶斯估计。具体地，条件概率的贝叶斯估计是</p>
<p>$$P_{\lambda}(X^{(j)}=a_{jl}|Y=c_k)=\frac{\sum_{i=1}^NI(x_i^{(j)},y_i=c_k)+\lambda}{\sum_{i=1}^NI(y_i=c_k)+S_j\lambda}$$</p>
<p>式中$\lambda \geq 0$，等价于在随机变量各个取值的频数上赋予一个正数λ&gt;0,当λ=0时就是极大似然估计。常取λ=1，这时称为拉普拉斯平滑(Laplace smoothing)。显然，对任何$l=1,2,\cdots ,S_j,k=1,2, \cdots ,K$，有</p>
<p>$$P_{\lambda}(X^{(j)}=a_{jl}|Y=c_k)&gt;0$$</p>
<p>$$\sum_{l=1}^{S_j}P(X^{(j)}=a_{jl}|Y=c_k)=1$$</p>
<p>表明上式确为一种概率分布，同样先验概率的贝叶斯估计是</p>
<p>$$P_{\lambda}(Y=c_k)=\frac{\sum_{i=1}^NI(y_i=c_k)+\lambda}{N+K\lambda}$$</p>
<h3 id="综合：python实现简单情感极性分析器"><a href="#综合：python实现简单情感极性分析器" class="headerlink" title="综合：python实现简单情感极性分析器"></a>综合：python实现简单情感极性分析器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># Filename: Bayes.py</span></span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log, exp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LaplaceEstimate</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""</span><br><span class="line">    拉普拉斯平滑处理的贝叶斯估计</span><br><span class="line">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.d = &#123;&#125;  <span class="comment"># [词-词频]的map</span></span><br><span class="line">        self.total = <span class="number">0.0</span>  <span class="comment"># 全部词的词频</span></span><br><span class="line">        self.none = <span class="number">1</span>  <span class="comment"># 当一个词不存在的时候，它的词频（等于0+1）</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">exists</span><span class="params">(self, key)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> key <span class="keyword">in</span> self.d</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getsum</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.total</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(self, key)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.exists(key):</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">False</span>, self.none</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span>, self.d[key]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getprob</span><span class="params">(self, key)</span>:</span></span><br><span class="line">        <span class="string">"""</span><br><span class="line">        估计先验概率</span><br><span class="line">        :param key: 词</span><br><span class="line">        :return: 概率</span><br><span class="line">        """</span></span><br><span class="line">        <span class="keyword">return</span> float(self.get(key)[<span class="number">1</span>]) / self.total</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">samples</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span><br><span class="line">        获取全部样本</span><br><span class="line">        :return:</span><br><span class="line">        """</span></span><br><span class="line">        <span class="keyword">return</span> self.d.keys()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(self, key, value)</span>:</span></span><br><span class="line">        self.total += value</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.exists(key):</span><br><span class="line">            self.d[key] = <span class="number">1</span></span><br><span class="line">            self.total += <span class="number">1</span></span><br><span class="line">        self.d[key] += value</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bayes</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.d = &#123;&#125;  <span class="comment"># [标签, 概率] map</span></span><br><span class="line">        self.total = <span class="number">0</span>  <span class="comment"># 全部词频</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> d <span class="keyword">in</span> data:  <span class="comment"># d是[[词链表], 标签]</span></span><br><span class="line">            c = d[<span class="number">1</span>]  <span class="comment"># c是分类</span></span><br><span class="line">            <span class="keyword">if</span> c <span class="keyword">not</span> <span class="keyword">in</span> self.d:</span><br><span class="line">                self.d[c] = LaplaceEstimate()  <span class="comment"># d[c]是概率统计工具</span></span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> d[<span class="number">0</span>]:</span><br><span class="line">                self.d[c].add(word, <span class="number">1</span>)  <span class="comment"># 统计词频</span></span><br><span class="line">        self.total = sum(map(<span class="keyword">lambda</span> x: self.d[x].getsum(), self.d.keys()))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        tmp = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> self.d:  <span class="comment"># 分类</span></span><br><span class="line">            tmp[c] = log(self.d[c].getsum()) - log(self.total)  <span class="comment"># P(Y=ck)</span></span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> x:</span><br><span class="line">                tmp[c] += log(self.d[c].getprob(word))          <span class="comment"># P(Xj=xj | Y=ck)</span></span><br><span class="line">        ret, prob = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> self.d:</span><br><span class="line">            now = <span class="number">0</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">for</span> otherc <span class="keyword">in</span> self.d:</span><br><span class="line">                    now += exp(tmp[otherc] - tmp[c])            <span class="comment"># 将对数还原为1/p</span></span><br><span class="line">                now = <span class="number">1</span> / now</span><br><span class="line">            <span class="keyword">except</span> OverflowError:</span><br><span class="line">                now = <span class="number">0</span></span><br><span class="line">            <span class="keyword">if</span> now &gt; prob:</span><br><span class="line">                ret, prob = c, now</span><br><span class="line">        <span class="keyword">return</span> (ret, prob)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sentiment</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.classifier = Bayes()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">segment</span><span class="params">(self, sent)</span>:</span></span><br><span class="line">        words = sent.split(<span class="string">' '</span>)</span><br><span class="line">        <span class="keyword">return</span> words</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, neg_docs, pos_docs)</span>:</span></span><br><span class="line">        data = []</span><br><span class="line">        <span class="keyword">for</span> sent <span class="keyword">in</span> neg_docs:</span><br><span class="line">            data.append([self.segment(sent), <span class="string">'消极'</span>])</span><br><span class="line">        <span class="keyword">for</span> sent <span class="keyword">in</span> pos_docs:</span><br><span class="line">            data.append([self.segment(sent), <span class="string">'积极'</span>])</span><br><span class="line">        self.classifier.train(data)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(self, sent)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.classifier.classify(self.segment(sent))</span><br><span class="line"></span><br><span class="line">s = Sentiment()</span><br><span class="line">s.train([<span class="string">'糟糕'</span>, <span class="string">'好 差劲'</span>,<span class="string">'坏'</span>,<span class="string">'好 坏'</span>], [<span class="string">'优秀'</span>, <span class="string">'很 好'</span>,<span class="string">'棒'</span>,<span class="string">'好 人'</span>]) <span class="comment"># 空格分词</span></span><br><span class="line"></span><br><span class="line">print(s.classify(<span class="string">"好 棒"</span>))</span><br></pre></td></tr></table></figure>
<p>输出结果:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="string">'积极'</span>, <span class="number">0.6451612903225805</span>)</span><br></pre></td></tr></table></figure>
</div><script type="text/javascript" src="/js/share.js?v=1.0.0" async></script><a data-url="http://keyunluo.github.io/2016/08/16/2016-08-16-statical-learning-4.html" data-id="citwxidve004rhlgleoj5uepn" class="article-share-link">分享到</a><div class="tags"><a href="/tags/机器学习/">机器学习</a></div><div class="post-nav"><a href="/2016/09/22/2016-09-22-hadoop-filesystem-1.html" class="pre">Hadoop源码学习(15)——文件系统(1)</a><a href="/2016/08/15/2016-08-15-statical-learning-3.html" class="next">统计学习方法——K近邻算法</a></div><div data-thread-key="2016/08/16/2016-08-16-statical-learning-4.html" data-title="统计学习方法——朴素贝叶斯法" data-url="http://keyunluo.github.io/2016/08/16/2016-08-16-statical-learning-4.html" class="ds-share flat"><div class="ds-share-inline"><ul class="ds-share-icons-16"><li data-toggle="ds-share-icons-more"><a href="javascript:void(0);" class="ds-more">分享到：</a></li><li><a href="javascript:void(0);" data-service="weibo" class="ds-weibo">微博</a></li><li><a href="javascript:void(0);" data-service="qzone" class="ds-qzone">QQ空间</a></li><li><a href="javascript:void(0);" data-service="qqt" class="ds-qqt">腾讯微博</a></li><li><a href="javascript:void(0);" data-service="wechat" class="ds-wechat">微信</a></li></ul><div class="ds-share-icons-more"></div></div></div><div data-thread-key="2016/08/16/2016-08-16-statical-learning-4.html" data-title="统计学习方法——朴素贝叶斯法" data-url="http://keyunluo.github.io/2016/08/16/2016-08-16-statical-learning-4.html" data-author-key="1" class="ds-thread"></div></div></div></div><div class="pure-u-1-4"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/AdvancedAlgorithms/">AdvancedAlgorithms</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/AlgorithmApplication/">AlgorithmApplication</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/BigData/">BigData</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DataBase/">DataBase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Life/">Life</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MachineLearning/">MachineLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Programming/">Programming</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/SourceCodeLearning/">SourceCodeLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tools/">Tools</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/二次排序/" style="font-size: 15px;">二次排序</a> <a href="/tags/elasticsearch/" style="font-size: 15px;">elasticsearch</a> <a href="/tags/大数据/" style="font-size: 15px;">大数据</a> <a href="/tags/Oracle/" style="font-size: 15px;">Oracle</a> <a href="/tags/DataBase/" style="font-size: 15px;">DataBase</a> <a href="/tags/VPN/" style="font-size: 15px;">VPN</a> <a href="/tags/生活/" style="font-size: 15px;">生活</a> <a href="/tags/毕业/" style="font-size: 15px;">毕业</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/UML/" style="font-size: 15px;">UML</a> <a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/PlantUML/" style="font-size: 15px;">PlantUML</a> <a href="/tags/sqoop/" style="font-size: 15px;">sqoop</a> <a href="/tags/Markdown/" style="font-size: 15px;">Markdown</a> <a href="/tags/Latex/" style="font-size: 15px;">Latex</a> <a href="/tags/CentOS/" style="font-size: 15px;">CentOS</a> <a href="/tags/Cloudera/" style="font-size: 15px;">Cloudera</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/数据压缩/" style="font-size: 15px;">数据压缩</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/OpenCV/" style="font-size: 15px;">OpenCV</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/10/13/2016-10-13-advanced-algorithm-assignment1.html">高级算法--作业1</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/05/2016-10-05-advanced-algorithm-3.html">高级算法(3)--Min-Cut-Max-Flow(2)-近似算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/05/2016-10-05-advanced-algorithm-2.html">高级算法(2)--Min-Cut-Max-Flow(1)-确定性算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/04/2016-10-04-advanced-algorithm-1.html">高级算法(1)--NP完全性与近似算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/04/2016-10-04-ubuntu16.04-opencv3-python3.html">Ubuntu16.04上编译OpenCV的Python3包</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/24/2016-09-24-compress-1.html">数据压缩(1) —— 概述</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/23/2016-09-23-statical-learning-5.html">统计学习方法——决策树</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/22/2016-09-22-hadoop-filesystem-1.html">Hadoop源码学习(15)——文件系统(1)</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/16/2016-08-16-statical-learning-4.html">统计学习方法——朴素贝叶斯法</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/15/2016-08-15-statical-learning-3.html">统计学习方法——K近邻算法</a></li></ul></div><div class="widget"><div class="comments-title"><i class="fa fa-comment-o"> 最近评论</i></div><div data-num-items="5" data-show-avatars="0" data-show-time="1" data-show-admin="0" data-excerpt-length="32" data-show-title="1" class="ds-recent-comments"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 外部链接</i></div><ul></ul><a href="http://keyunluo.github.io/algorithm" title="个人算法练习" target="_blank">个人算法练习</a></div><div class="widget"><div class="widget-title"><i class="fa fa-bar-chart"> 访客</i></div><a href="http://info.flagcounter.com/uNxw"><img src="http://s07.flagcounter.com/count2/uNxw/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_3/labels_0/pageviews_0/flags_0/percent_0/" alt="" border="0"></a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">流光.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=1.0.0"><script>var duoshuoQuery = {short_name:'streamers'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script><script type="text/javascript" src="/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-76470846-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?945b21807344d0260f24455bbd82dfea";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>