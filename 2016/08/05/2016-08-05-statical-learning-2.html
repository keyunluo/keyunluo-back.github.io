<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Coder On The Road"><title>统计学习方法——感知机 | 流光</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.1.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.2/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/2.2.3/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">统计学习方法——感知机</h1><a id="logo" href="/.">流光</a><p class="description">他跑啊跑啊，只为追上那个曾经被寄予厚望的自己</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/guestbook/"><i class="fa fa-comments"> 留言</i></a><a href="/resource/share"><i class="fa fa-download"> 资源</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-4-5"><div class="content_container"><div class="post"><h1 class="post-title">统计学习方法——感知机</h1><div class="post-meta">Aug 5, 2016<span> | </span><span class="category"><a href="/categories/MachineLearning/">MachineLearning</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-thread-key="2016/08/05/2016-08-05-statical-learning-2.html" href="/2016/08/05/2016-08-05-statical-learning-2.html#comments" class="ds-thread-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#感知机模型"><span class="toc-number">1.</span> <span class="toc-text">感知机模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#感知机学习策略"><span class="toc-number">2.</span> <span class="toc-text">感知机学习策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#感知机学习算法的原始形式"><span class="toc-number">3.</span> <span class="toc-text">感知机学习算法的原始形式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#感知机学习算法的对偶形式"><span class="toc-number">4.</span> <span class="toc-text">感知机学习算法的对偶形式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#感知机学习算法的收敛性"><span class="toc-number">5.</span> <span class="toc-text">感知机学习算法的收敛性</span></a></li></ol></div></div><div class="post-content"><blockquote>
<p><strong>本节内容：</strong>感知机(perceptron)是二类分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别取+1和-1二值，感知机对应于输入空间(特征空间)中将实例划分为正负两类的分离超平面，本节对应于统计学习方法第二章的内容。</p>
</blockquote>
<a id="more"></a>
<h2 id="感知机模型"><a href="#感知机模型" class="headerlink" title="感知机模型"></a>感知机模型</h2><ol>
<li><p>定义</p>
<p> 假设输入空间(特征空间)是 $ \mathcal{X} \subseteq \mathcal{R}^n $ ,输出空间是$\mathcal{y} = \{+1,-1\}$. 输入$x \in \mathcal{X}$表示实例的特征向量，对应于输入空间(特征空间)的点；输出$y \in \mathcal{Y}$表示实例的类别。由输入空间到输出空间的如下函数：</p>
<p> $$f(x)=sign(w \cdot x+b)$$</p>
<p> 被称为感知机，其中，$w$和$b$称为感知机模型参数，$w \in \mathcal{R}^n $称为权值或权值向量，$b \in \mathcal{R} $叫做偏置，$w \cdot x $ 表示$w$和$x$的内积，$sign$是符号函数，即：</p>
<p> $$
 f(x)=
 \begin{cases}
 +1&amp; \text{x &gt;= 0} \\
 -1&amp; \text{x &lt; 0}
 \end{cases}
 $$</p>
<p> 感知机是一种线性分类模型，属于判别模型，感知机模型的架设空间是定义在特征空间中的所有线性分类模型l(linear classification model)或线性分类器(linear classifier)，即函数集合$\{f \mid f(x)=w \cdot x+b \}$</p>
</li>
<li><p>感知机的几何解释</p>
<p> 线性方程 $ w \cdot x +b =0 $ 所代表的超平面将特征空间划分为正负两个部分。</p>
<p> <img src="/resource/blog/2016-08/perceptron.jpg" alt="感知机模型"></p>
<p> 这个平面（2维时退化为直线）称为分离超平面。</p>
</li>
</ol>
<h2 id="感知机学习策略"><a href="#感知机学习策略" class="headerlink" title="感知机学习策略"></a>感知机学习策略</h2><ol>
<li><p>数据集的线性可分性</p>
<p> 给定一个数据集： $T = \{(x_1,y_1),(x_2,y_2),\cdots ,(x_N,y_N)\}$,其中，$x_i \in \mathcal{X} = \mathcal{R}^n , y_i \in \mathcal{Y} = \{+1,-1\}, i = 1,2,\cdots ,N$,如果存在某个超平面$S$ : $w \cdot x + b =0$ 能够将数据集的正实例点和负实例点完全正确的划分到超平面的两侧，则称数据集$T$为线性可分数据集,否则称数据集$T$线性不可分。</p>
</li>
<li><p>感知机的学习策略</p>
<p> 假定数据集线性可分，我们希望找到一个合理的损失函数。</p>
<p> 一个朴素的想法是采用误分类点的总数，但是这样的损失函数不是参数$w，b$的连续可导函数，不可导自然不能把握函数的变化，也就不易优化（不知道什么时候该终止训练，或终止的时机不是最优的）。</p>
<p> 另一个想法是选择所有误分类点到超平面S的总距离。为此，先定义点$x_0$到平面$S$的距离：</p>
<p> $$\frac{1}{\Vert w \Vert} \vert w \cdot x_0 + b \vert $$</p>
<p> 其中，$\Vert w \Vert$是$w$的$L_2$范数。</p>
<p> 考虑到误分类时-y&gt;0,去掉绝对值符号，得到误分类点到超平面S的距离公式：</p>
<p> $$-\frac{1}{\Vert w \Vert} y_i ( w \cdot x_i + b)$$</p>
<p> 假设所有误分类点构成集合M，那么所有误分类点到超平面S的总距离为:</p>
<p> $$-\frac{1}{\Vert w \Vert} \sum_{x_i \in M}y_i ( w \cdot x_i + b)$$</p>
<p> 不考虑系数，得到感知机$sign(w \cdot x +b$学习的损失函数：</p>
<p> $$L(w,b)= - \sum_{x_i \in M} y_i(w \cdot x_i +b)$$</p>
<p> 其中$M$为误分类点的集合，这个损失函数就是感知机学习的经验风险函数。</p>
</li>
</ol>
<h2 id="感知机学习算法的原始形式"><a href="#感知机学习算法的原始形式" class="headerlink" title="感知机学习算法的原始形式"></a>感知机学习算法的原始形式</h2><ol>
<li><p>概述</p>
<p> 感知机学习算法是对以下最优化问题的算法,求参数$w,b$，使损失函数极小化：</p>
<p> $$min_{w,b} L(w,b)= - \sum_{x_i \in M} y_i(w \cdot x_i +b)$$</p>
<p> 感知机学习算法是误分类驱动的，先随机选取一个超平面，然后用随机梯度下降法(Stochastic Gradient Decent)不断极小化上述损失函数。损失函数的梯度由：</p>
<p> $$ \nabla_w L(w,b) = - \sum_{x_i \in M} y_ix_i $$</p>
<p> $$ \nabla_b L(w,b) = - \sum_{x_i \in M} y_i $$</p>
<p> 给出，所谓梯度，是一个向量，指向的是标量场增长最快的方向，长度是最大变化率。所谓标量场，指的是空间中任意一个点的属性都可以用一个标量表示的场。</p>
<p> 随机选择一个误分类点$(x_i,y_i)$，对$w,b$进行更新：</p>
<p> $$
 w \leftarrow w + \eta y_ix_i \\
 b \leftarrow b+ \eta y_i
 $$</p>
<p> $\eta(0&lt;\eta \leq 1)$是步长，在统计学习中称为学习率。损失函数的参数加上梯度上升的反方向，于是就梯度下降了。所以，上述迭代可以使损失函数不断减小，直到为0。</p>
</li>
<li><p>感知器学习算法</p>
<p> 输入：训练数据集$T=\{(x_1,y_1),(x_2,y_2), \cdots , (x_N,y_N)\},其中x_i \in \mathcal{X} = \mathcal{R}^n,y_i \in \mathcal{Y} = \{+1,-1 \},i=1,2,\cdots ,N;学习率\eta(0&lt;\eta \leq 1);$</p>
<p> 输出：$w,b; 感知机模型 f(x) = sign(w \cdot x +b)$</p>
<p> (1) 选取初值 $w_0,b_0$</p>
<p> (2) 在训练集中选取数据$(x_i,y_i)$</p>
<p> (3) 如果$y_i(w \cdot x_i +b) \leq 0 $</p>
<p> $$
 w \leftarrow w + \eta y_ix_i  \\
 b \leftarrow b+ \eta y_i
 $$</p>
<p> (4) 转至(2)，直到训练集中没有误分类点</p>
</li>
<li><p>一个例子</p>
<p> 如下图所示的训练数据集，其正实例点是$x_1=(3,3)^T,x_2=(4,3)^T$,负实例点是$x_3=(1,1)^T$，试用感知机学习算法的原始形式求解感知机模型$f(x)=sign(w \cdot x +b),其中w = (w^{(1)},w^{(2)})^T,x = (x^{(1)},x^{(2)})^T$</p>
<p> <img src="/resource/blog/2016-08/perceptronexample.jpg" alt="感知机实例"></p>
<p> 解： 构建最优化问题,按照上述算法求解$w,b,\eta = 1$</p>
<p> (1) 取初值$w_0=0,b_0 =0$</p>
<p> (2) 对$x_1=(3,3)^T,y_1(w_0 \cdot x_1 +b_0) = 0$,未能被正确分类，更新$w,b$:</p>
<p> $$
 w_1 = w_0 +y_1x_1=(3,3)^T  \\
 b_1 = b_0 +y_1 = 1
 $$</p>
<p> 得到线性模型</p>
<p> $$w_1 \cdot x + b_1 = 3x^{(1)}+3x^{(2)}+1$$</p>
<p> (3) 对$x_1,x_2，显然有y_i(w_1 \cdot x_i +b_1)&gt;0，被正确分类，不修改w,b;对于x_3=(1,1)^T,y_3(w_1 \cdot x_3 +b_1)&lt;0，被误分类，更新w,b:$</p>
<p> $$
 w_2 = w_1 +y_3x_3=(2,2)^T \\
 b_2 = b_1 + y_3 = 0
 $$</p>
<p> 得到线性模型： $w_2 \cdot x + b_2 = 2x^{(1)}+2x^{(2)}$</p>
<p> 如此继续下去，直到：</p>
<p> $$
 w_7 =(1,1)^T ,b_7=-3
 $$</p>
<p> 对于所有的点都没有误分类点，损失函数达到极小。</p>
</li>
<li><p>Python代码实现</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> animation</span><br><span class="line"></span><br><span class="line">training_set = [[(<span class="number">3</span>, <span class="number">3</span>), <span class="number">1</span>], [(<span class="number">4</span>, <span class="number">3</span>), <span class="number">1</span>], [(<span class="number">1</span>, <span class="number">1</span>), <span class="number">-1</span>]]</span><br><span class="line">w = [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">b = <span class="number">0</span></span><br><span class="line">eta = <span class="number">1</span></span><br><span class="line">history = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新变量:w,b</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(item)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> w, b, eta , history</span><br><span class="line">    w[<span class="number">0</span>] += eta * item[<span class="number">1</span>] * item[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    w[<span class="number">1</span>] += eta * item[<span class="number">1</span>] * item[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">    b += eta * item[<span class="number">1</span>]</span><br><span class="line">    print(w, b)</span><br><span class="line">    history.append([copy.copy(w), b])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算y(w*xi+b)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cal</span><span class="params">(item)</span>:</span></span><br><span class="line">    res = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(item[<span class="number">0</span>])):</span><br><span class="line">        res += item[<span class="number">0</span>][i] * w[i]</span><br><span class="line">    res += b</span><br><span class="line">    res *= item[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断超平面是否正确</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check</span><span class="params">()</span>:</span></span><br><span class="line">    flag = <span class="keyword">False</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> training_set:</span><br><span class="line">        <span class="keyword">if</span> cal(item) &lt;= <span class="number">0</span>:</span><br><span class="line">            flag = <span class="keyword">True</span></span><br><span class="line">            update(item)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> flag:</span><br><span class="line">        print(<span class="string">"RESULT: w: "</span> + str(w) + <span class="string">" b: "</span> + str(b))</span><br><span class="line">    <span class="keyword">return</span> flag</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> check(): <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># first set up the figure, the axis, and the plot element we want to animate</span></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = plt.axes(xlim=(<span class="number">0</span>, <span class="number">4</span>), ylim=(<span class="number">-2</span>, <span class="number">2</span>))</span><br><span class="line">    line, = ax.plot([], [], <span class="string">'g'</span>, lw=<span class="number">2</span>)</span><br><span class="line">    label = ax.text([], [], <span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialization function: plot the background of each frame</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init</span><span class="params">()</span>:</span></span><br><span class="line">        line.set_data([], [])</span><br><span class="line">        x, y, x_, y_ = [], [], [], []</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> training_set:</span><br><span class="line">            <span class="comment"># 正实例</span></span><br><span class="line">            <span class="keyword">if</span> p[<span class="number">1</span>] &gt; <span class="number">0</span>:</span><br><span class="line">                x.append(p[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">                y.append(p[<span class="number">0</span>][<span class="number">1</span>])</span><br><span class="line">            <span class="comment"># 负实例</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                x_.append(p[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">                y_.append(p[<span class="number">0</span>][<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        plt.plot(x,y,<span class="string">'bo'</span>)</span><br><span class="line">        plt.plot(x_,y_,<span class="string">'rx'</span>)</span><br><span class="line">        plt.legend([<span class="string">'超平面'</span>,<span class="string">'正实例'</span>, <span class="string">'负实例'</span>], loc=<span class="string">'upper left'</span>)</span><br><span class="line">        plt.axis([<span class="number">-1</span>, <span class="number">5</span>, <span class="number">-1</span>, <span class="number">5</span>])</span><br><span class="line">        plt.grid(<span class="keyword">True</span>)</span><br><span class="line">        plt.xlabel(<span class="string">'x'</span>)</span><br><span class="line">        plt.ylabel(<span class="string">'y'</span>)</span><br><span class="line"></span><br><span class="line">        plt.title(<span class="string">'感知机算法实验——原始形式'</span>)</span><br><span class="line">        <span class="keyword">return</span> line, label</span><br><span class="line"></span><br><span class="line">    <span class="comment"># animation function.  this is called sequentially</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">animate</span><span class="params">(i)</span>:</span></span><br><span class="line">        <span class="keyword">global</span> history, ax, line, label</span><br><span class="line"></span><br><span class="line">        w = history[i][<span class="number">0</span>]</span><br><span class="line">        b = history[i][<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        hyperplane = <span class="string">"&#123;0&#125;*x1+&#123;1&#125;*x2+&#123;2&#125;=0"</span>.format(w[<span class="number">0</span>],w[<span class="number">1</span>],b)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> w[<span class="number">1</span>] == <span class="number">0</span>:</span><br><span class="line">            line.set_data([<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">            label.set_text(<span class="string">"第%d次运算:"</span>%(i+<span class="number">1</span>)+<span class="string">"超平面:"</span>+hyperplane)</span><br><span class="line">            label.set_position([<span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">            <span class="keyword">return</span> line, label</span><br><span class="line">        x1 = <span class="number">-6</span></span><br><span class="line">        y1 = -(b + w[<span class="number">0</span>] * x1) / w[<span class="number">1</span>]</span><br><span class="line">        x2 = <span class="number">6</span></span><br><span class="line">        y2 = -(b + w[<span class="number">0</span>] * x2) / w[<span class="number">1</span>]</span><br><span class="line">        line.set_data([x1, x2], [y1, y2])</span><br><span class="line">        x1 = <span class="number">0</span></span><br><span class="line">        y1 = -(b + w[<span class="number">0</span>] * x1) / w[<span class="number">1</span>]</span><br><span class="line">        label.set_text(<span class="string">"第%d次运算:"</span>%(i+<span class="number">1</span>)+<span class="string">"超平面:"</span>+hyperplane)</span><br><span class="line">        label.set_position([x1, y1])</span><br><span class="line">        <span class="keyword">return</span> line, label</span><br><span class="line"></span><br><span class="line">    print(history)</span><br><span class="line">    anim = animation.FuncAnimation(fig, animate, init_func=init, frames=len(history), interval=<span class="number">1000</span>, repeat=<span class="keyword">True</span>,blit=<span class="keyword">True</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    anim.save(<span class="string">'perceptron-animate.gif'</span>, fps=<span class="number">2</span>, writer=<span class="string">'imagemagick'</span>)</span><br></pre></td></tr></table></figure>
<p>动画显示如下：
<img src="/resource/blog/2016-08/perceptron-animate.gif" alt="perceptron-animate"></p>
<h2 id="感知机学习算法的对偶形式"><a href="#感知机学习算法的对偶形式" class="headerlink" title="感知机学习算法的对偶形式"></a>感知机学习算法的对偶形式</h2><ol>
<li><p>概述
 对偶指的是，将$w和b$表示为测试数据$i$的线性组合形式，通过求解系数得到$w和b$。具体说来，如果对误分类点i逐步修改$wb$修改了$n$次，则$w，b关于i$的增量分别为增量${\alpha}_iy_ix_i和{\alpha}_iy_i，这里{\alpha}_i=n_i\eta$，则最终求解到的参数分别表示为：</p>
<p> $$
 w \leftarrow w + \eta y_ix_i \\
 b \leftarrow b + \eta y_i
 $$</p>
</li>
<li><p>算法</p>
<p> 输入：线性可分的数据集$T=\{(x_1,y_1),(x_2,y_2), \cdots , (x_N,y_N)\},其中x_i \in \mathcal{X} = \mathcal{R}^n,y_i \in \mathcal{Y} = \{+1,-1 \},i=1,2,\cdots ,N;学习率\eta(0&lt;\eta \leq 1);$</p>
<p> 输出：$\alpha,b; 感知机模型 f(x) = sign(\sum_{j=1}^N \alpha_jy_jx_j \cdot x +b),其中\alpha = (\alpha_1,\alpha_2,\cdots ,\alpha_N)^T$</p>
<p> (1) 选取初值 $\alpha \leftarrow 0,b \leftarrow 0$</p>
<p> (2) 在训练集中选取数据$(x_i,y_i)$</p>
<p> (3) 如果$y_i(\sum_{j=1}^N \alpha_jy_jx_j \cdot x +b) \leq 0 $</p>
<p> $$
 \alpha_i \leftarrow \alpha_i + \eta  \\
 b \leftarrow b+ \eta y_i
 $$</p>
<p> (4) 转至(2)，直到训练集中没有误分类点</p>
<p> 对偶形式中的训练实例仅以内积的形式出现，为了方便，可以预先将训练集中实例间的内积计算出来并以矩阵的形式存储，这个矩阵被称为Gram矩阵：</p>
<p> $$ G = [x_i \cdot x_j]_{N \times N} $$</p>
</li>
<li><p>代码</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> animation</span><br><span class="line"></span><br><span class="line">training_set = [[(<span class="number">3</span>, <span class="number">3</span>), <span class="number">1</span>], [(<span class="number">4</span>, <span class="number">3</span>), <span class="number">1</span>], [(<span class="number">1</span>, <span class="number">1</span>), <span class="number">-1</span>]]</span><br><span class="line"><span class="comment"># training_set = np.array([[[3, 3], 1], [[4, 3], 1], [[1, 1], -1], [[5, 2], -1]])</span></span><br><span class="line">a = np.zeros(len(training_set), np.float)</span><br><span class="line">b = <span class="number">0.0</span></span><br><span class="line">Gram = <span class="keyword">None</span></span><br><span class="line">eta = <span class="number">1</span></span><br><span class="line"><span class="comment"># y = np.array(training_set[:, 1])</span></span><br><span class="line">y = np.empty((len(training_set)), np.float)</span><br><span class="line">x = np.empty((len(training_set), <span class="number">2</span>), np.float)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(training_set)):</span><br><span class="line">    x[i] = training_set[i][<span class="number">0</span>]</span><br><span class="line">    y[i] = training_set[i][<span class="number">1</span>]</span><br><span class="line">history = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算Gram矩阵</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cal_gram</span><span class="params">()</span>:</span></span><br><span class="line">    g = np.empty((len(training_set), len(training_set)), np.int)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(training_set)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(training_set)):</span><br><span class="line">            g[i][j] = np.dot(training_set[i][<span class="number">0</span>], training_set[j][<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">return</span> g</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新变量:a,b</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(i)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> a, b, eta</span><br><span class="line">    a[i] += eta</span><br><span class="line">    b = b + y[i]</span><br><span class="line">    history.append([np.dot(a * y, x), b])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算判断条件</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cal</span><span class="params">(i)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> a, b, x, y</span><br><span class="line">    res = np.dot(a * y, Gram[i])</span><br><span class="line">    res = (res + b) * y[i]</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断超平面是否正确</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">global</span> a, b, x, y</span><br><span class="line">    flag = <span class="keyword">False</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(training_set)):</span><br><span class="line">        <span class="keyword">if</span> cal(i) &lt;= <span class="number">0</span>:</span><br><span class="line">            flag = <span class="keyword">True</span></span><br><span class="line">            update(i)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> flag:</span><br><span class="line">        w = np.dot(a * y, x)</span><br><span class="line">        print(<span class="string">"RESULT: w: "</span> + str(w) + <span class="string">" b: "</span> + str(b))</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    Gram = cal_gram()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> check(): <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># first set up the figure, the axis, and the plot element we want to animate</span></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = plt.axes(xlim=(<span class="number">0</span>, <span class="number">4</span>), ylim=(<span class="number">-2</span>, <span class="number">2</span>))</span><br><span class="line">    line, = ax.plot([], [], <span class="string">'g'</span>, lw=<span class="number">2</span>)</span><br><span class="line">    label = ax.text([], [], <span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialization function: plot the background of each frame</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init</span><span class="params">()</span>:</span></span><br><span class="line">        line.set_data([], [])</span><br><span class="line">        x, y, x_, y_ = [], [], [], []</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> training_set:</span><br><span class="line">            <span class="comment"># 正实例</span></span><br><span class="line">            <span class="keyword">if</span> p[<span class="number">1</span>] &gt; <span class="number">0</span>:</span><br><span class="line">                x.append(p[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">                y.append(p[<span class="number">0</span>][<span class="number">1</span>])</span><br><span class="line">            <span class="comment"># 负实例</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                x_.append(p[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">                y_.append(p[<span class="number">0</span>][<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        plt.plot(x,y,<span class="string">'bo'</span>)</span><br><span class="line">        plt.plot(x_,y_,<span class="string">'rx'</span>)</span><br><span class="line">        plt.legend([<span class="string">'超平面'</span>,<span class="string">'正实例'</span>, <span class="string">'负实例'</span>], loc=<span class="string">'upper left'</span>)</span><br><span class="line">        plt.axis([<span class="number">-1</span>, <span class="number">5</span>, <span class="number">-1</span>, <span class="number">5</span>])</span><br><span class="line">        plt.grid(<span class="keyword">True</span>)</span><br><span class="line">        plt.xlabel(<span class="string">'x'</span>)</span><br><span class="line">        plt.ylabel(<span class="string">'y'</span>)</span><br><span class="line"></span><br><span class="line">        plt.title(<span class="string">'感知机算法实验——对偶形式'</span>)</span><br><span class="line">        <span class="keyword">return</span> line, label</span><br><span class="line"></span><br><span class="line">    <span class="comment"># animation function.  this is called sequentially</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">animate</span><span class="params">(i)</span>:</span></span><br><span class="line">        <span class="keyword">global</span> history, ax, line, label</span><br><span class="line"></span><br><span class="line">        w = history[i][<span class="number">0</span>]</span><br><span class="line">        b = history[i][<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        hyperplane = <span class="string">"&#123;0&#125;*x1+&#123;1&#125;*x2+&#123;2&#125;=0"</span>.format(w[<span class="number">0</span>],w[<span class="number">1</span>],b)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> w[<span class="number">1</span>] == <span class="number">0</span>:</span><br><span class="line">            line.set_data([<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">            label.set_text(<span class="string">"第%d次运算:"</span>%(i+<span class="number">1</span>)+<span class="string">"超平面:"</span>+hyperplane)</span><br><span class="line">            label.set_position([<span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">            <span class="keyword">return</span> line, label</span><br><span class="line">        x1 = <span class="number">-6</span></span><br><span class="line">        y1 = -(b + w[<span class="number">0</span>] * x1) / w[<span class="number">1</span>]</span><br><span class="line">        x2 = <span class="number">6</span></span><br><span class="line">        y2 = -(b + w[<span class="number">0</span>] * x2) / w[<span class="number">1</span>]</span><br><span class="line">        line.set_data([x1, x2], [y1, y2])</span><br><span class="line">        x1 = <span class="number">0</span></span><br><span class="line">        y1 = -(b + w[<span class="number">0</span>] * x1) / w[<span class="number">1</span>]</span><br><span class="line">        label.set_text(<span class="string">"第%d次运算:"</span>%(i+<span class="number">1</span>)+<span class="string">"超平面:"</span>+hyperplane)</span><br><span class="line">        label.set_position([x1, y1])</span><br><span class="line">        <span class="keyword">return</span> line, label</span><br><span class="line"></span><br><span class="line">    print(history)</span><br><span class="line">    anim = animation.FuncAnimation(fig, animate, init_func=init, frames=len(history), interval=<span class="number">1000</span>, repeat=<span class="keyword">True</span>,blit=<span class="keyword">True</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    anim.save(<span class="string">'perceptron-animate2.gif'</span>, fps=<span class="number">2</span>, writer=<span class="string">'imagemagick'</span>)</span><br></pre></td></tr></table></figure>
<h2 id="感知机学习算法的收敛性"><a href="#感知机学习算法的收敛性" class="headerlink" title="感知机学习算法的收敛性"></a>感知机学习算法的收敛性</h2><p>设训练数据集$T=\{(x_1,y_1),(x_2,y_2), \cdots , (x_N,y_N)\}是线性可分的,其中x_i \in \mathcal{X} = \mathcal{R}^n,y_i \in \mathcal{Y} = \{+1,-1 \},i=1,2,\cdots ,N;学习率\eta(0&lt;\eta \leq 1);$,则：</p>
<p>(1) 存在满足条件$\Vert \hat{w}_{opt} \Vert = 1的超平面 \hat{w}_{opt} \cdot x + b_{opt} =0 将训练数据集完全正确分开；且存在\gamma &gt;0,对所有的 i=1,2,\cdots , N $ :</p>
<p>$$y_i(\hat{w}]_{opt} \cdot \hat{x}]_i) = y_i(w_{opt} \cdot x_i + b_{opt}) \geq \gamma $$</p>
<p>(2) 令 $R = {max}_{1 \leq i \leq N} \Vert \hat{x}_i \Vert$,则感知机算法在训练集上的错误分类次数k满足不等式：</p>
<p>$$k \leq {\left( \frac{R}{\gamma} \right)}^2$$</p>
</div><script type="text/javascript" src="/js/share.js?v=1.0.0" async></script><a data-url="http://keyunluo.github.io/2016/08/05/2016-08-05-statical-learning-2.html" data-id="cix04cfe8002f1jglupukpakv" class="article-share-link">分享到</a><div class="tags"><a href="/tags/机器学习/">机器学习</a></div><div class="post-nav"><a href="/2016/08/06/2016-08-06-hadoop-io-1.html" class="pre">Hadoop源码学习(5)——Hadoop-Common-IO</a><a href="/2016/08/04/2016-08-04-hadoop-common-conf-2.html" class="next">Hadoop源码学习(4)——Hadoop-Common-Conf(2)</a></div><div data-thread-key="2016/08/05/2016-08-05-statical-learning-2.html" data-title="统计学习方法——感知机" data-url="http://keyunluo.github.io/2016/08/05/2016-08-05-statical-learning-2.html" class="ds-share flat"><div class="ds-share-inline"><ul class="ds-share-icons-16"><li data-toggle="ds-share-icons-more"><a href="javascript:void(0);" class="ds-more">分享到：</a></li><li><a href="javascript:void(0);" data-service="weibo" class="ds-weibo">微博</a></li><li><a href="javascript:void(0);" data-service="qzone" class="ds-qzone">QQ空间</a></li><li><a href="javascript:void(0);" data-service="qqt" class="ds-qqt">腾讯微博</a></li><li><a href="javascript:void(0);" data-service="wechat" class="ds-wechat">微信</a></li></ul><div class="ds-share-icons-more"></div></div></div><div data-thread-key="2016/08/05/2016-08-05-statical-learning-2.html" data-title="统计学习方法——感知机" data-url="http://keyunluo.github.io/2016/08/05/2016-08-05-statical-learning-2.html" data-author-key="1" class="ds-thread"></div></div></div></div><div class="pure-u-1-5"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/AdvancedAlgorithms/">AdvancedAlgorithms</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/AlgorithmApplication/">AlgorithmApplication</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/BigData/">BigData</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DataBase/">DataBase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DistributedSystem/">DistributedSystem</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/FileAndStorage/">FileAndStorage</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Life/">Life</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MachineLearning/">MachineLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Programming/">Programming</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/SourceCodeLearning/">SourceCodeLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tools/">Tools</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/PlantUML/" style="font-size: 15px;">PlantUML</a> <a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/VPN/" style="font-size: 15px;">VPN</a> <a href="/tags/Oracle/" style="font-size: 15px;">Oracle</a> <a href="/tags/DataBase/" style="font-size: 15px;">DataBase</a> <a href="/tags/elasticsearch/" style="font-size: 15px;">elasticsearch</a> <a href="/tags/大数据/" style="font-size: 15px;">大数据</a> <a href="/tags/sqoop/" style="font-size: 15px;">sqoop</a> <a href="/tags/生活/" style="font-size: 15px;">生活</a> <a href="/tags/毕业/" style="font-size: 15px;">毕业</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/UML/" style="font-size: 15px;">UML</a> <a href="/tags/二次排序/" style="font-size: 15px;">二次排序</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/CentOS/" style="font-size: 15px;">CentOS</a> <a href="/tags/Cloudera/" style="font-size: 15px;">Cloudera</a> <a href="/tags/Markdown/" style="font-size: 15px;">Markdown</a> <a href="/tags/Latex/" style="font-size: 15px;">Latex</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/数据压缩/" style="font-size: 15px;">数据压缩</a> <a href="/tags/存储引擎/" style="font-size: 15px;">存储引擎</a> <a href="/tags/LSM树/" style="font-size: 15px;">LSM树</a> <a href="/tags/分布式系统/" style="font-size: 15px;">分布式系统</a> <a href="/tags/OpenCV/" style="font-size: 15px;">OpenCV</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/12/23/2016-12-23-distributed-system-1.html">分布式系统——课程总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/23/2016-12-22-data-mining.html">数据挖掘——课程总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/16/2016-11-16-skiplist1.html">SkipList 跳跃表(1) ——基本介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/16/2016-11-16-lsm1.html">LSM Tree (1)</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/15/2016-11-15-hash.html">Hash存储引擎</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/03/2016-11-03-advanced-algorithm-assignment2.html">高级算法--作业2</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/13/2016-10-13-advanced-algorithm-assignment1.html">高级算法--作业1</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/06/2016-10-06-advanced-algorithm-3.html">高级算法(3)--Min-Cut-Max-Flow(2)-近似算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/05/2016-10-05-advanced-algorithm-2.html">高级算法(2)--Min-Cut-Max-Flow(1)-确定性算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/04/2016-10-04-advanced-algorithm-1.html">高级算法(1)--NP完全性与近似算法</a></li></ul></div><div class="widget"><div class="comments-title"><i class="fa fa-comment-o"> 最近评论</i></div><div data-num-items="5" data-show-avatars="0" data-show-time="1" data-show-admin="0" data-excerpt-length="32" data-show-title="1" class="ds-recent-comments"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 外部链接</i></div><ul></ul><a href="http://keyunluo.github.io/algorithm" title="个人算法练习" target="_blank">个人算法练习</a></div><div class="widget"><div class="widget-title"><i class="fa fa-bar-chart"> 访客</i></div><a href="http://info.flagcounter.com/uNxw"><img src="http://s07.flagcounter.com/count2/uNxw/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_3/labels_0/pageviews_0/flags_0/percent_0/" alt="" border="0"></a></div></div></div><div class="pure-u-1 pure-u-md-4-5"><div id="footer">© <a href="/." rel="nofollow">流光.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=1.0.0"><script>var duoshuoQuery = {short_name:'streamers'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script><script type="text/javascript" src="/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-76470846-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?945b21807344d0260f24455bbd82dfea";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><div id="script" type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></div><script type="text/javascript" src="/js/mathjax/2.7-latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>